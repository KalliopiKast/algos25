[
  {
    "objectID": "weeks/week-9.html",
    "href": "weeks/week-9.html",
    "title": "Week 9",
    "section": "",
    "text": "Important\n\n\n\nDue date: Exam 1 released on Fri, Feb 35, due Mon, Feb 28 at 11:59pm",
    "crumbs": [
      "Weekly materials",
      "Week 9"
    ]
  },
  {
    "objectID": "weeks/week-9.html#prepare",
    "href": "weeks/week-9.html#prepare",
    "title": "Week 9",
    "section": "Prepare",
    "text": "Prepare\nNo readings this week.",
    "crumbs": [
      "Weekly materials",
      "Week 9"
    ]
  },
  {
    "objectID": "weeks/week-9.html#participate",
    "href": "weeks/week-9.html#participate",
    "title": "Week 9",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lecture 16 - MLR: Inference\nüñ•Ô∏è Lecture 17 - MLR: Inference conditions + multicollinearity",
    "crumbs": [
      "Weekly materials",
      "Week 9"
    ]
  },
  {
    "objectID": "weeks/week-9.html#practice",
    "href": "weeks/week-9.html#practice",
    "title": "Week 9",
    "section": "Practice",
    "text": "Practice\nüìã Application Exercise 8 - Rail Trail",
    "crumbs": [
      "Weekly materials",
      "Week 9"
    ]
  },
  {
    "objectID": "weeks/week-9.html#perform",
    "href": "weeks/week-9.html#perform",
    "title": "Week 9",
    "section": "Perform",
    "text": "Perform\n‚úÖ Exam 2\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly materials",
      "Week 9"
    ]
  },
  {
    "objectID": "weeks/week-7.html",
    "href": "weeks/week-7.html",
    "title": "Week 7",
    "section": "",
    "text": "Important\n\n\n\nDue dates:\n\nHW 2 - Friday, Feb 18\nProject ideas - Friday, Feb 18",
    "crumbs": [
      "Weekly materials",
      "Week 7"
    ]
  },
  {
    "objectID": "weeks/week-7.html#prepare",
    "href": "weeks/week-7.html#prepare",
    "title": "Week 7",
    "section": "Prepare",
    "text": "Prepare\nüìñ Read Tidy Modeling in R Chp 8: Feature engineering with recipes",
    "crumbs": [
      "Weekly materials",
      "Week 7"
    ]
  },
  {
    "objectID": "weeks/week-7.html#participate",
    "href": "weeks/week-7.html#participate",
    "title": "Week 7",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lecture 12 - MLR: Feature engineering\nüñ•Ô∏è Lecture 13 - MLR: Feature engineering (cont.)",
    "crumbs": [
      "Weekly materials",
      "Week 7"
    ]
  },
  {
    "objectID": "weeks/week-7.html#practice",
    "href": "weeks/week-7.html#practice",
    "title": "Week 7",
    "section": "Practice",
    "text": "Practice\nüìã Application Exercise 5 - The Office",
    "crumbs": [
      "Weekly materials",
      "Week 7"
    ]
  },
  {
    "objectID": "weeks/week-7.html#perform",
    "href": "weeks/week-7.html#perform",
    "title": "Week 7",
    "section": "Perform",
    "text": "Perform\n‚úçÔ∏è HW 2 - Multiple linear regression\nüìÇ Project - Topic ideas\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly materials",
      "Week 7"
    ]
  },
  {
    "objectID": "weeks/week-5.html",
    "href": "weeks/week-5.html",
    "title": "Week 5",
    "section": "",
    "text": "Important\n\n\n\n\nDue date: Lab 2 - Fri, Feb 4, 5pm ET\nExam 1 released on Fri, Feb 4, due Mon, Feb 7 at 11:59pm",
    "crumbs": [
      "Weekly materials",
      "Week 5"
    ]
  },
  {
    "objectID": "weeks/week-5.html#prepare",
    "href": "weeks/week-5.html#prepare",
    "title": "Week 5",
    "section": "Prepare",
    "text": "Prepare\nüìñ Read Introduction to Modern Statistics, Sec 8.1: Indicator and categorical predictors\nüìñ Read Introduction to Modern Statistics, Sec 8.2: Many predictors in a model\nüìñ Read Introduction to Modern Statistics, Sec 8.3: Adjusted R-squared",
    "crumbs": [
      "Weekly materials",
      "Week 5"
    ]
  },
  {
    "objectID": "weeks/week-5.html#participate",
    "href": "weeks/week-5.html#participate",
    "title": "Week 5",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lab 3 - Coffee ratings\nüñ•Ô∏è Lecture 8 - Multiple linear regression (MLR)\nüñ•Ô∏è Lecture 9 - Exam 1 review",
    "crumbs": [
      "Weekly materials",
      "Week 5"
    ]
  },
  {
    "objectID": "weeks/week-5.html#practice",
    "href": "weeks/week-5.html#practice",
    "title": "Week 5",
    "section": "Practice",
    "text": "Practice\nüìã Application Exercise 4 - Exam 1 Review",
    "crumbs": [
      "Weekly materials",
      "Week 5"
    ]
  },
  {
    "objectID": "weeks/week-5.html#perform",
    "href": "weeks/week-5.html#perform",
    "title": "Week 5",
    "section": "Perform",
    "text": "Perform\n‚å®Ô∏è Lab 3 - Coffee ratings\n‚úÖ Exam 1\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly materials",
      "Week 5"
    ]
  },
  {
    "objectID": "weeks/week-3.html",
    "href": "weeks/week-3.html",
    "title": "Week 3",
    "section": "",
    "text": "Important\n\n\n\n\nWe‚Äôre back to in person classes this week! See here for class locations. And don‚Äôt forget to wear your mask! üò∑\nDue dates:\n\nAE 2: Fri, Jan 21, 11:59pm ET",
    "crumbs": [
      "Weekly materials",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week-3.html#prepare",
    "href": "weeks/week-3.html#prepare",
    "title": "Week 3",
    "section": "Prepare",
    "text": "Prepare\nüìñ Read Introduction to Modern Statistics, Sec 24.1: Case study: Sandwich store\nüìñ Read Introduction to Modern Statistics, Sec 24.2: Randomization test for the slope\nüìñ Read Introduction to Modern Statistics, Sec 24.3: Bootstrap confidence interval for the slope",
    "crumbs": [
      "Weekly materials",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week-3.html#participate",
    "href": "weeks/week-3.html#participate",
    "title": "Week 3",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lecture 4 - SLR: Prediction + model evaluation\nüñ•Ô∏è Lecture 5 - SLR: Simulation-based inference",
    "crumbs": [
      "Weekly materials",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week-3.html#practice",
    "href": "weeks/week-3.html#practice",
    "title": "Week 3",
    "section": "Practice",
    "text": "Practice\nüìã Application Exercise 2 - Bike rentals in DC",
    "crumbs": [
      "Weekly materials",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week-3.html#perform",
    "href": "weeks/week-3.html#perform",
    "title": "Week 3",
    "section": "Perform",
    "text": "Perform\nNone.\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly materials",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week-15.html",
    "href": "weeks/week-15.html",
    "title": "Week 15",
    "section": "",
    "text": "Important\n\n\n\nDue dates: Tue, Apr 19 - HW 5",
    "crumbs": [
      "Weekly materials",
      "Week 15"
    ]
  },
  {
    "objectID": "weeks/week-15.html#participate",
    "href": "weeks/week-15.html#participate",
    "title": "Week 15",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lecture 28 - Wrap up",
    "crumbs": [
      "Weekly materials",
      "Week 15"
    ]
  },
  {
    "objectID": "weeks/week-15.html#practice",
    "href": "weeks/week-15.html#practice",
    "title": "Week 15",
    "section": "Practice",
    "text": "Practice\nüìã Application Exercise 13 - A Tale of Two Creeks",
    "crumbs": [
      "Weekly materials",
      "Week 15"
    ]
  },
  {
    "objectID": "weeks/week-15.html#perform",
    "href": "weeks/week-15.html#perform",
    "title": "Week 15",
    "section": "Perform",
    "text": "Perform\n‚úçÔ∏è HW 5 - Statistics experience\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly materials",
      "Week 15"
    ]
  },
  {
    "objectID": "weeks/week-13.html",
    "href": "weeks/week-13.html",
    "title": "Week 13",
    "section": "",
    "text": "Important\n\n\n\nDue dates:\n\nLab 6 - Friday, April 8\nProject drafts - Sunday, April 10",
    "crumbs": [
      "Weekly materials",
      "Week 13"
    ]
  },
  {
    "objectID": "weeks/week-13.html#participate",
    "href": "weeks/week-13.html#participate",
    "title": "Week 13",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lecture 24 - MultiLR: Prediction + inferential models\nüñ•Ô∏è Lecture 25 - MultiLR: Predictive models",
    "crumbs": [
      "Weekly materials",
      "Week 13"
    ]
  },
  {
    "objectID": "weeks/week-13.html#practice",
    "href": "weeks/week-13.html#practice",
    "title": "Week 13",
    "section": "Practice",
    "text": "Practice\nüìã Application Exercise 11 - Volcanoes",
    "crumbs": [
      "Weekly materials",
      "Week 13"
    ]
  },
  {
    "objectID": "weeks/week-13.html#perform",
    "href": "weeks/week-13.html#perform",
    "title": "Week 13",
    "section": "Perform",
    "text": "Perform\n‚úçÔ∏è HW 4 - Multinomial logistic regression\nüíª Lab 6 - Why Many Americans Don‚Äôt Vote\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly materials",
      "Week 13"
    ]
  },
  {
    "objectID": "weeks/week-11.html",
    "href": "weeks/week-11.html",
    "title": "Week 11",
    "section": "",
    "text": "Important\n\n\n\nDue dates:\n\nLab 5 - Friday, Mar 25\nHW 3 - Friday, Mar 25",
    "crumbs": [
      "Weekly materials",
      "Week 11"
    ]
  },
  {
    "objectID": "weeks/week-11.html#prepare",
    "href": "weeks/week-11.html#prepare",
    "title": "Week 11",
    "section": "Prepare",
    "text": "Prepare\nNo additional readings this week. Catch up with previously assigned readings if you‚Äôve fallen behind.",
    "crumbs": [
      "Weekly materials",
      "Week 11"
    ]
  },
  {
    "objectID": "weeks/week-11.html#participate",
    "href": "weeks/week-11.html#participate",
    "title": "Week 11",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lecture 20 - LR: Prediction / classification\nüñ•Ô∏è Lecture 21 - LR: Model validation",
    "crumbs": [
      "Weekly materials",
      "Week 11"
    ]
  },
  {
    "objectID": "weeks/week-11.html#practice",
    "href": "weeks/week-11.html#practice",
    "title": "Week 11",
    "section": "Practice",
    "text": "Practice\nüìã Application Exercise 10 - Flight delays",
    "crumbs": [
      "Weekly materials",
      "Week 11"
    ]
  },
  {
    "objectID": "weeks/week-11.html#perform",
    "href": "weeks/week-11.html#perform",
    "title": "Week 11",
    "section": "Perform",
    "text": "Perform\n‚úçÔ∏è HW 3 - Logistic regression and log transformation\n‚å®Ô∏è Lab 5 - General Social Survey\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly materials",
      "Week 11"
    ]
  },
  {
    "objectID": "weeks/week-1.html",
    "href": "weeks/week-1.html",
    "title": "Week 1",
    "section": "",
    "text": "Important\n\n\n\nClasses are virtual this week. Find Zoom links here.",
    "crumbs": [
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week-1.html#prepare",
    "href": "weeks/week-1.html#prepare",
    "title": "Week 1",
    "section": "Prepare",
    "text": "Prepare\nüìñ Read the syllabus\nüìñ Read the support resources",
    "crumbs": [
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week-1.html#participate",
    "href": "weeks/week-1.html#participate",
    "title": "Week 1",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lab 0 -Meet+ greet\nüñ•Ô∏è Lecture 1 - Welcome to STA 210",
    "crumbs": [
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week-1.html#practice",
    "href": "weeks/week-1.html#practice",
    "title": "Week 1",
    "section": "Practice",
    "text": "Practice\nüìã AE 0 - Movies",
    "crumbs": [
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week-1.html#perform",
    "href": "weeks/week-1.html#perform",
    "title": "Week 1",
    "section": "Perform",
    "text": "Perform\n‚å®Ô∏è Lab 0 - Meet + greet\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "supplemental/model-selection-criteria.html",
    "href": "supplemental/model-selection-criteria.html",
    "title": "Model Selection Criteria: AIC & BIC",
    "section": "",
    "text": "Note\n\n\n\nThe following supplemental notes were created by Dr.¬†Maria Tackett for STA 210. They are provided for students who want to dive deeper into the mathematics behind regression and reflect some of the material covered in STA 211: Mathematics of Regression. Additional supplemental notes will be added throughout the semester.\nThis document discusses some of the mathematical details of Akaike‚Äôs Information Criterion (AIC) and Schwarz‚Äôs Bayesian Information Criterion (BIC). We assume the reader knowledge of the matrix form for multiple linear regression.Please see Matrix Notation for Multiple Linear Regression for a review.",
    "crumbs": [
      "Supplemental notes",
      "Model selection criteria"
    ]
  },
  {
    "objectID": "supplemental/model-selection-criteria.html#maximum-likelihood-estimation-of-boldsymbolbeta-and-sigma",
    "href": "supplemental/model-selection-criteria.html#maximum-likelihood-estimation-of-boldsymbolbeta-and-sigma",
    "title": "Model Selection Criteria: AIC & BIC",
    "section": "Maximum Likelihood Estimation of \\(\\boldsymbol{\\beta}\\) and \\(\\sigma\\)",
    "text": "Maximum Likelihood Estimation of \\(\\boldsymbol{\\beta}\\) and \\(\\sigma\\)\nTo understand the formulas for AIC and BIC, we will first briefly explain the likelihood function and maximum likelihood estimates for regression.\nLet \\(\\mathbf{Y}\\) be \\(n \\times 1\\) matrix of responses, \\(\\mathbf{X}\\), the \\(n \\times (p+1)\\) matrix of predictors, and \\(\\boldsymbol{\\beta}\\), \\((p+1) \\times 1\\) matrix of coefficients. If the multiple linear regression model is correct then,\n\\[\n\\mathbf{Y} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma^2)\n\\tag{1}\\]\nWhen we do linear regression, our goal is to estimate the unknown parameters \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\) from Equation¬†1. In Matrix Notation for Multiple Linear Regression, we showed a way to estimate these parameters using matrix alegbra. Another approach for estimating \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\) is using maximum likelihood estimation.\nA likelihood function is used to summarise the evidence from the data in support of each possible value of a model parameter. Using Equation¬†1, we will write the likelihood function for linear regression as\n\\[\nL(\\mathbf{X}, \\mathbf{Y}|\\boldsymbol{\\beta}, \\sigma^2) = \\prod\\limits_{i=1}^n (2\\pi \\sigma^2)^{-\\frac{1}{2}} \\exp\\bigg\\{-\\frac{1}{2\\sigma^2}\\sum\\limits_{i=1}^n(Y_i - \\mathbf{X}_i \\boldsymbol{\\beta})^T(Y_i - \\mathbf{X}_i \\boldsymbol{\\beta})\\bigg\\}\n\\tag{2}\\]\nwhere \\(Y_i\\) is the \\(i^{th}\\) response and \\(\\mathbf{X}_i\\) is the vector of predictors for the \\(i^{th}\\) observation. One approach estimating \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\) is to find the values of those parameters that maximize the likelihood in Equation¬†2, i.e.¬†maximum likelhood estimation. To make the calculations more manageable, instead of maximizing the likelihood function, we will instead maximize its logarithm, i.e.¬†the log-likelihood function. The values of the parameters that maximize the log-likelihood function are those that maximize the likelihood function. The log-likelihood function we will maximize is\n\\[\n\\begin{aligned}\n\\log L(\\mathbf{X}, \\mathbf{Y}|\\boldsymbol{\\beta}, \\sigma^2) &= \\sum\\limits_{i=1}^n -\\frac{1}{2}\\log(2\\pi\\sigma^2) -\\frac{1}{2\\sigma^2}\\sum\\limits_{i=1}^n(Y_i - \\mathbf{X}_i \\boldsymbol{\\beta})^T(Y_i - \\mathbf{X}_i \\boldsymbol{\\beta}) \\\\\n&= -\\frac{n}{2}\\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})^T(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})\\\\\n\\end{aligned}\n\\tag{3}\\]\n\nThe maximum likelihood estimate of \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\) are \\[\n\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y} \\hspace{10mm} \\hat{\\sigma}^2 = \\frac{1}{n}(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})^T(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta}) = \\frac{1}{n}RSS\n\\tag{4}\\]\nwhere \\(RSS\\) is the residual sum of squares. Note that the maximum likelihood estimate is not exactly equal to the estimate of \\(\\sigma^2\\) we typically use \\(\\frac{RSS}{n-p-1}\\). This is because the maximum likelihood estimate of \\(\\sigma^2\\) in Equation¬†4 is a biased estimator of \\(\\sigma^2\\). When \\(n\\) is much larger than the number of predictors \\(p\\), then the differences in these two estimates are trivial.",
    "crumbs": [
      "Supplemental notes",
      "Model selection criteria"
    ]
  },
  {
    "objectID": "supplemental/model-selection-criteria.html#aic",
    "href": "supplemental/model-selection-criteria.html#aic",
    "title": "Model Selection Criteria: AIC & BIC",
    "section": "AIC",
    "text": "AIC\nAkaike‚Äôs Information Criterion (AIC) is\n\\[\nAIC = -2 \\log L + 2(p+1)\n\\tag{5}\\]\nwhere \\(\\log L\\) is the log-likelihood. This is the general form of AIC that can be applied to a variety of models, but for now, let‚Äôs focus on AIC for mutliple linear regression.\n\\[\n\\begin{aligned}\nAIC &= -2 \\log L + 2(p+1) \\\\\n&= -2\\bigg[-\\frac{n}{2}\\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})^T(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})\\bigg] + 2(p+1) \\\\\n&= n\\log\\big(2\\pi\\frac{RSS}{n}\\big) + \\frac{1}{RSS/n}RSS \\\\\n&= n\\log(2\\pi) + n\\log(RSS) - n\\log(n) + 2(p+1)\n\\end{aligned}\n\\tag{6}\\]",
    "crumbs": [
      "Supplemental notes",
      "Model selection criteria"
    ]
  },
  {
    "objectID": "supplemental/model-selection-criteria.html#bic",
    "href": "supplemental/model-selection-criteria.html#bic",
    "title": "Model Selection Criteria: AIC & BIC",
    "section": "BIC",
    "text": "BIC\n[To be added.]",
    "crumbs": [
      "Supplemental notes",
      "Model selection criteria"
    ]
  },
  {
    "objectID": "supplemental/mlr-matrix.html",
    "href": "supplemental/mlr-matrix.html",
    "title": "Matrix Notation for Multiple Linear Regression",
    "section": "",
    "text": "Note\n\n\n\nThe following supplemental notes were created by Dr.¬†Maria Tackett for STA 210. They are provided for students who want to dive deeper into the mathematics behind regression and reflect some of the material covered in STA 211: Mathematics of Regression. Additional supplemental notes will be added throughout the semester.\nThis document provides the details for the matrix notation for multiple linear regression. We assume the reader has familiarity with some linear algebra. Please see Chapter 1 of An Introduction to Statistical Learning for a brief review of linear algebra.",
    "crumbs": [
      "Supplemental notes",
      "MLR matrix notation"
    ]
  },
  {
    "objectID": "supplemental/mlr-matrix.html#introduction",
    "href": "supplemental/mlr-matrix.html#introduction",
    "title": "Matrix Notation for Multiple Linear Regression",
    "section": "Introduction",
    "text": "Introduction\nSuppose we have \\(n\\) observations. Let the \\(i^{th}\\) be \\((x_{i1}, \\ldots, x_{ip}, y_i)\\), such that \\(x_{i1}, \\ldots, x_{ip}\\) are the explanatory variables (predictors) and \\(y_i\\) is the response variable. We assume the data can be modeled using the least-squares regression model, such that the mean response for a given combination of explanatory variables follows the form in Equation¬†1.\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p\n\\tag{1}\\]\nWe can write the response for the \\(i^{th}\\) observation as shown in Equation¬†2\n\\[\ny_i = \\beta_0 + \\beta_1 x_{i1} + \\dots + \\beta_p x_{ip} + \\epsilon_i\n\\tag{2}\\]\nsuch that \\(\\epsilon_i\\) is the amount \\(y_i\\) deviates from \\(\\mu\\{y|x_{i1}, \\ldots, x_{ip}\\}\\), the mean response for a given combination of explanatory variables. We assume each \\(\\epsilon_i \\sim N(0,\\sigma^2)\\), where \\(\\sigma^2\\) is a constant variance for the distribution of the response \\(y\\) for any combination of explanatory variables \\(x_1, \\ldots, x_p\\).",
    "crumbs": [
      "Supplemental notes",
      "MLR matrix notation"
    ]
  },
  {
    "objectID": "supplemental/mlr-matrix.html#matrix-representation-for-the-regression-model",
    "href": "supplemental/mlr-matrix.html#matrix-representation-for-the-regression-model",
    "title": "Matrix Notation for Multiple Linear Regression",
    "section": "Matrix Representation for the Regression Model",
    "text": "Matrix Representation for the Regression Model\nWe can represent the Equation¬†1 and Equation¬†2 using matrix notation. Let\n\\[\n\\mathbf{Y} = \\begin{bmatrix}y_1 \\\\ y_2 \\\\ \\vdots \\\\y_n\\end{bmatrix}\n\\hspace{15mm}\n\\mathbf{X} = \\begin{bmatrix}x_{11} & x_{12} & \\dots & x_{1p} \\\\\nx_{21} & x_{22} & \\dots & x_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\nx_{n1} & x_{n2} & \\dots & x_{np} \\end{bmatrix}\n\\hspace{15mm}\n\\boldsymbol{\\beta}= \\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\\\ \\vdots \\\\ \\beta_p \\end{bmatrix}\n\\hspace{15mm}\n\\boldsymbol{\\epsilon}= \\begin{bmatrix}\\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{bmatrix}\n\\tag{3}\\]\nThus,\n\\[\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\\]\nTherefore the estimated response for a given combination of explanatory variables and the associated residuals can be written as\n\\[\n\\hat{\\mathbf{Y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\hspace{10mm} \\mathbf{e} = \\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\n\\tag{4}\\]",
    "crumbs": [
      "Supplemental notes",
      "MLR matrix notation"
    ]
  },
  {
    "objectID": "supplemental/mlr-matrix.html#estimating-the-coefficients",
    "href": "supplemental/mlr-matrix.html#estimating-the-coefficients",
    "title": "Matrix Notation for Multiple Linear Regression",
    "section": "Estimating the Coefficients",
    "text": "Estimating the Coefficients\nThe least-squares model is the one that minimizes the sum of the squared residuals. Therefore, we want to find the coefficients, \\(\\hat{\\boldsymbol{\\beta}}\\) that minimizes\n\\[\n\\sum\\limits_{i=1}^{n} e_{i}^2 = \\mathbf{e}^T\\mathbf{e} = (\\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}})^T(\\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}})\n\\tag{5}\\]\nwhere \\(\\mathbf{e}^T\\), the transpose of the matrix \\(\\mathbf{e}\\).\n\\[\n(\\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}})^T(\\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}) = (\\mathbf{Y}^T\\mathbf{Y} -\n\\mathbf{Y}^T \\mathbf{X}\\hat{\\boldsymbol{\\beta}} - (\\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{Y} +\n\\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{X}\n\\hat{\\boldsymbol{\\beta}})\n\\tag{6}\\]\nNote that \\((\\mathbf{Y^T}\\mathbf{X}\\hat{\\boldsymbol{\\beta}})^T = \\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{Y}\\). Since these are both constants (i.e.¬†\\(1\\times 1\\) vectors), \\(\\mathbf{Y^T}\\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{Y}\\). Thus, Equation¬†7 becomes\n\\[\n\\mathbf{Y}^T\\mathbf{Y} - 2 \\mathbf{X}^T\\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{Y} + \\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{X}\n\\hat{\\boldsymbol{\\beta}}\n\\tag{7}\\]\nSince we want to find the \\(\\hat{\\boldsymbol{\\beta}}\\) that minimizes Equation¬†5, will find the value of \\(\\hat{\\boldsymbol{\\beta}}\\) such that the derivative with respect to \\(\\hat{\\boldsymbol{\\beta}}\\) is equal to 0.\n\\[\n\\begin{aligned}\n\\frac{\\partial \\mathbf{e}^T\\mathbf{e}}{\\partial \\hat{\\boldsymbol{\\beta}}} & = \\frac{\\partial}{\\partial \\hat{\\boldsymbol{\\beta}}}(\\mathbf{Y}^T\\mathbf{Y} - 2 \\mathbf{X}^T\\hat{\\boldsymbol{\\beta}}{}^T\\mathbf{Y} + \\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}}) = 0 \\\\\n&\\Rightarrow - 2 \\mathbf{X}^T\\mathbf{Y} + 2 \\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} = 0 \\\\\n& \\Rightarrow 2 \\mathbf{X}^T\\mathbf{Y} = 2 \\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\\n& \\Rightarrow \\mathbf{X}^T\\mathbf{Y} = \\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\\n& \\Rightarrow (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\\n& \\Rightarrow (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y} = \\mathbf{I}\\hat{\\boldsymbol{\\beta}}\n\\end{aligned}\n\\tag{8}\\]\nThus, the estimate of the model coefficients is \\(\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}\\).",
    "crumbs": [
      "Supplemental notes",
      "MLR matrix notation"
    ]
  },
  {
    "objectID": "supplemental/mlr-matrix.html#variance-covariance-matrix-of-the-coefficients",
    "href": "supplemental/mlr-matrix.html#variance-covariance-matrix-of-the-coefficients",
    "title": "Matrix Notation for Multiple Linear Regression",
    "section": "Variance-covariance matrix of the coefficients",
    "text": "Variance-covariance matrix of the coefficients\nWe will use two properties to derive the form of the variance-covariance matrix of the coefficients:\n\n\\(E[\\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T] = \\sigma^2I\\)\n\\(\\hat{\\boldsymbol{\\beta}} = \\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1}\\epsilon\\)\n\nFirst, we will show that \\(E[\\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T] = \\sigma^2I\\)\n\\[\n\\begin{aligned}\nE[\\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T] &= E \\begin{bmatrix}\\epsilon_1  & \\epsilon_2 & \\dots & \\epsilon_n \\end{bmatrix}\\begin{bmatrix}\\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{bmatrix}  \\\\\n& = E \\begin{bmatrix} \\epsilon_1^2  & \\epsilon_1 \\epsilon_2 & \\dots & \\epsilon_1 \\epsilon_n \\\\\n\\epsilon_2 \\epsilon_1 & \\epsilon_2^2 & \\dots & \\epsilon_2 \\epsilon_n \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\epsilon_n \\epsilon_1 & \\epsilon_n \\epsilon_2 & \\dots & \\epsilon_n^2\n\\end{bmatrix} \\\\\n& = \\begin{bmatrix} E[\\epsilon_1^2]  & E[\\epsilon_1 \\epsilon_2] & \\dots & E[\\epsilon_1 \\epsilon_n] \\\\\nE[\\epsilon_2 \\epsilon_1] & E[\\epsilon_2^2] & \\dots & E[\\epsilon_2 \\epsilon_n] \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nE[\\epsilon_n \\epsilon_1] & E[\\epsilon_n \\epsilon_2] & \\dots & E[\\epsilon_n^2]\n\\end{bmatrix}\n\\end{aligned}\n\\tag{9}\\]\nRecall, the regression assumption that the errors \\(\\epsilon_i's\\) are Normally distributed with mean 0 and variance \\(\\sigma^2\\). Thus, \\(E(\\epsilon_i^2) = Var(\\epsilon_i) = \\sigma^2\\) for all \\(i\\). Additionally, recall the regression assumption that the errors are uncorrelated, i.e.¬†\\(E(\\epsilon_i \\epsilon_j) = Cov(\\epsilon_i, \\epsilon_j) = 0\\) for all \\(i,j\\). Using these assumptions, we can write Equation¬†9 as\n\\[\nE[\\mathbf{\\epsilon}\\mathbf{\\epsilon}^T]  = \\begin{bmatrix} \\sigma^2  & 0 & \\dots & 0 \\\\\n0 & \\sigma^2  & \\dots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\dots & \\sigma^2\n\\end{bmatrix} = \\sigma^2 \\mathbf{I}\n\\tag{10}\\]\nwhere \\(\\mathbf{I}\\) is the \\(n \\times n\\) identity matrix.\nNext, we show that \\(\\hat{\\boldsymbol{\\beta}} = \\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1}\\epsilon\\).\nRecall that the \\(\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}\\) and \\(\\mathbf{Y} = \\mathbf{X}\\mathbf{\\beta} + \\mathbf{\\epsilon}\\). Then,\n\\[\n\\begin{aligned}\n\\hat{\\boldsymbol{\\beta}} &= (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y} \\\\\n&= (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T(\\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}) \\\\\n&= \\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T \\mathbf{\\epsilon} \\\\\n\\end{aligned}\n\\tag{11}\\]\nUsing these two properties, we derive the form of the variance-covariance matrix for the coefficients. Note that the covariance matrix is \\(E[(\\hat{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})(\\hat{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})^T]\\)\n\\[\n\\begin{aligned}\nE[(\\hat{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})(\\hat{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})^T] &= E[(\\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T \\boldsymbol{\\epsilon} - \\boldsymbol{\\beta})(\\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T \\boldsymbol{\\epsilon} - \\boldsymbol{\\beta})^T]\\\\\n& = E[(\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T \\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}] \\\\\n& = (\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T E[\\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T]\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\\\\n& = (\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T (\\sigma^2\\mathbf{I})\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\\\\n&= \\sigma^2\\mathbf{I}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\\\\n& = \\sigma^2\\mathbf{I}(\\mathbf{X}^T\\mathbf{X})^{-1}\\\\\n&  = \\sigma^2(\\mathbf{X}^T\\mathbf{X})^{-1} \\\\\n\\end{aligned}\n\\tag{12}\\]",
    "crumbs": [
      "Supplemental notes",
      "MLR matrix notation"
    ]
  },
  {
    "objectID": "project-tips-resources.html",
    "href": "project-tips-resources.html",
    "title": "Project tips + resources",
    "section": "",
    "text": "R Data Sources for Regression Analysis\nFiveThirtyEight data\nTidyTuesday\n\n\n\n\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "project-tips-resources.html#data-sources",
    "href": "project-tips-resources.html#data-sources",
    "title": "Project tips + resources",
    "section": "",
    "text": "R Data Sources for Regression Analysis\nFiveThirtyEight data\nTidyTuesday\n\n\n\n\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "project-tips-resources.html#tips",
    "href": "project-tips-resources.html#tips",
    "title": "Project tips + resources",
    "section": "Tips",
    "text": "Tips\n\nAsk questions if any of the expectations are unclear.\nCode: In your write up your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your qmd file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you‚Äôre welcome to show that portion.\n\nMerge conflicts will happen, issues will arise, and that‚Äôs fine! Commit and push often, and ask questions when stuck.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nAll team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works.",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "project-tips-resources.html#formatting-communication-tips",
    "href": "project-tips-resources.html#formatting-communication-tips",
    "title": "Project tips + resources",
    "section": "Formatting + communication tips",
    "text": "Formatting + communication tips\n\nSuppress Code, Warnings, & Messages\n\nInclude the following code in a code chunk at the top of your .qmd file to suppress all code, warnings, and other messages. Use the code chunk header {r set-up, include = FALSE} to suppress this set up code.\n\nknitr::opts_chunk$set(echo = FALSE,\n                      warning = FALSE, \n                      message = FALSE)\n\n\nHeaders\n\nUse headers to clearly label each section.\nInspect the document outline to review your headers and sub-headers.\n\n\n\nReferences\n\nInclude all references in a section called ‚ÄúReferences‚Äù at the end of the report.\nThis course does not have specific requirements for formatting citations and references.\n\n\n\nAppendix\n\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called ‚ÄúAppendix‚Äù.\nThe items in the appendix should be properly labeled.\nThe appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix.\n\n\n\nResize figures\nResize plots and figures, so you have more space for the narrative.\n\n\nArranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\nIf you‚Äôre using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid. See the documentation and examples here.\n\n\nPlot titles and axis labels\nBe sure all plot titles and axis labels are visible and easy to read.\n\nUse informative titles, not variable names, for titles and axis labels.\n\n‚ùå NO! The x-axis is hard to read because the names overlap.\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n‚úÖ YES! Names are readable\n\nggplot(data = mpg, aes(y = manufacturer)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\nDo a little more to make the plot look professional!\n\nInformative title and axis labels\nFlipped coordinates to make names readable\nArranged bars based on count\nCapitalized manufacturer names\nOptional: Added color - Use a coordinated color scheme throughout paper / presentation\nOptional: Applied a theme - Use same theme throughout paper / presentation\n\n\nmpg %&gt;%\n  count(manufacturer) %&gt;%\n  mutate(manufacturer = str_to_title(manufacturer)) %&gt;%\n  ggplot(aes(y = fct_reorder(manufacturer,n), x = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  labs(x = \"Manufacturer\", \n       y = \"Count\", \n       title = \"The most common manufacturer is Dodge\") +\n  theme_minimal() \n\n\n\n\n\n\n\n\n\n\nTables and model output\n\nUse the kable function from the knitr package to neatly output all tables and model output. This will also ensure all model coefficients are displayed.\n\nUse the digits argument to display only 3 or 4 significant digits.\nUse the caption argument to add captions to your table.\n\n\n\nmodel &lt;- lm(mpg ~ hp, data = mtcars)\ntidy(model) %&gt;%\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n30.099\n1.634\n18.421\n0\n\n\nhp\n-0.068\n0.010\n-6.742\n0\n\n\n\n\n\n\n\nGuidelines for communicating results\n\nDon‚Äôt use variable names in your narrative! Use descriptive terms, so the reader understands your narrative without relying on the data dictionary.\n\n‚ùå There is a negative linear relationship between mpg and hp.\n‚úÖ There is a negative linear relationship between a car‚Äôs fuel economy (in miles per gallon) and its horsepower.\n\nKnow your audience: Your report should be written for a general audience who has an understanding of statistics at the level of STA 210.\nAvoid subject matter jargon: Don‚Äôt assume the audience knows all of the specific terminology related to your subject area. If you must use jargon, include a brief definition the first time you introduce a term.\nTell the ‚Äúso what‚Äù: Your report and presentation should be more than a list of interpretations and technical definitions. Focus on what the results mean, i.e.¬†what you want the audience to know about your topic after reading your report or viewing your presentation.\n\n‚ùå For every one unit increase in horsepower, we expect the miles per gallon to decrease by 0.068 units, on average.\n‚úÖ If the priority is to have good fuel economy, then one should choose a car with lower horsepower. Based on our model, the fuel economy is expected to decrease, on average, by 0.68 miles per gallon for every 10 additional horsepower.\n\nTell a story: All visualizations, tables, model output, and narrative should tell a cohesive story!\nUse one voice: Though multiple people are writing the report, it should read as if it‚Äôs from a single author. At least one team member should read through the report before submission to ensure it reads like a cohesive document.",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "project-tips-resources.html#additional-resources",
    "href": "project-tips-resources.html#additional-resources",
    "title": "Project tips + resources",
    "section": "Additional resources",
    "text": "Additional resources\n\nR for Data Science\nQuarto Documentation\nData visualization\n\nggplot2 Reference\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practice Introduction\nPatchwork R Package",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "title": "Attribution-ShareAlike 4.0 International",
    "section": "Creative Commons Attribution-ShareAlike 4.0 International Public License",
    "text": "Creative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (‚ÄúPublic License‚Äù). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 ‚Äì Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter‚Äôs License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 ‚Äì Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part; and\nB. produce, reproduce, and Share Adapted Material.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor ‚Äì Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. Additional offer from the Licensor ‚Äì Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter‚Äôs License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\n\n\nSection 3 ‚Äì License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter‚Äôs License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter‚Äôs License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter‚Äôs License You apply.\n\n\n\nSection 4 ‚Äì Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 ‚Äì Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 ‚Äì Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 ‚Äì Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 ‚Äì Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the ‚ÄúLicensor.‚Äù The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark ‚ÄúCreative Commons‚Äù or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org."
  },
  {
    "objectID": "hw/hw-1.html",
    "href": "hw/hw-1.html",
    "title": "HW 1 - In-person voting trends",
    "section": "",
    "text": "In this assignment, you‚Äôll use simple linear regression to explore the percent of votes cast in-person in the 2020 U.S. election based on the county‚Äôs political leanings.\n\n\nIn this assignment, you will‚Ä¶\n\nFit and interpret simple linear regression models\nAssess the conditions for simple linear regression.\nCreate and interpret spatial data visualizations using R.\nContinue developing a workflow for reproducible data analysis."
  },
  {
    "objectID": "hw/hw-1.html#introduction",
    "href": "hw/hw-1.html#introduction",
    "title": "HW 1 - In-person voting trends",
    "section": "",
    "text": "In this assignment, you‚Äôll use simple linear regression to explore the percent of votes cast in-person in the 2020 U.S. election based on the county‚Äôs political leanings.\n\n\nIn this assignment, you will‚Ä¶\n\nFit and interpret simple linear regression models\nAssess the conditions for simple linear regression.\nCreate and interpret spatial data visualizations using R.\nContinue developing a workflow for reproducible data analysis."
  },
  {
    "objectID": "hw/hw-1.html#getting-started",
    "href": "hw/hw-1.html#getting-started",
    "title": "HW 1 - In-person voting trends",
    "section": "Getting started",
    "text": "Getting started\n\nLog in to RStudio\n\nGo to https://vm-manage.oit.duke.edu/containers and login with your Duke NetID and Password.\nClick STA210 to log into the Docker container. You should now see the RStudio environment.\n\n\n\nClone the repo & start new RStudio project\n\nGo to the course organization at github.com/sta210-s22 organization on GitHub. Click on the repo with the prefix hw-1. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you‚Äôll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ‚ûõ New Project ‚ûõVersion Control ‚ûõ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick hw-1-voting.qmd to open the template R Markdown file. This is where you will write up your code and narrative for the lab."
  },
  {
    "objectID": "hw/hw-1.html#packages",
    "href": "hw/hw-1.html#packages",
    "title": "HW 1 - In-person voting trends",
    "section": "Packages",
    "text": "Packages\nThe following packages will be used in this assignment:\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(scales)"
  },
  {
    "objectID": "hw/hw-1.html#data-2020-election",
    "href": "hw/hw-1.html#data-2020-election",
    "title": "HW 1 - In-person voting trends",
    "section": "Data: 2020 Election",
    "text": "Data: 2020 Election\nThere are multiple data sets for this assignment. Use the code below to load the data.\n\nelection_nc &lt;- read_csv(\"data/nc-election-2020.csv\") %&gt;%\n  mutate(fips = as.integer(FIPS))\ncounty_map_data &lt;-  read_csv(\"data/nc-county-map-data.csv\")\nelection_sample &lt;- read_csv(\"data/us-election-2020-sample.csv\")\n\nThe county-level election data in election_nc and election_sample are from The Economist GitHub repo. The data were originally analyzed in the July 2021 article In-person voting really did accelerate covid-19‚Äôs spread in America. For this analysis, we will focus on the following variables:\n\ninperson_pct: The proportion of a county‚Äôs votes cast in-person in the 2020 election\npctTrump_2016: The proportion of a county‚Äôs votes cast for Donald Trump in the 2016 election\n\nThe data in county_map_data were obtained from the maps package in R. We will not analyze any of the variables in this data set but will use it to help create maps in the assignment. Click here to see the documentation for the maps package. Click here for code examples."
  },
  {
    "objectID": "hw/hw-1.html#exercises",
    "href": "hw/hw-1.html#exercises",
    "title": "HW 1 - In-person voting trends",
    "section": "Exercises",
    "text": "Exercises\nDue to COVID-19 pandemic, many states made alternatives in-person voting, such as voting by mail, more widely available for the 2020 U.S. election. The general consensus was that voters who were more Democratic leaning would be more likely to vote by mail, while more Republican leaning voters would largely vote in-person. This was supported by multiple surveys, including this survey conducted by Pew Research.\nThe goal of this analysis is to use regression analysis to explore the relationship between a county‚Äôs political leanings and the proportion of votes cast in-person in 2020. The ultimate question we want to answer is ‚ÄúDid counties with more Republican leanings have a larger proportion of votes cast in-person in the 2020 election?‚Äù\nWe will use the proportion of votes cast for Donald Trump in 2016 (pctTrump_2016) as a measure of a county‚Äôs political leaning. Counties with a higher proportion of votes for Trump in 2016 are considered to have more Republican leanings.\n\n\n\n\n\n\nNote\n\n\n\nAll narrative should be written in complete sentences, and all visualizations should have informative titles and axis labels.\n\n\n\nPart 1: Counties in North Carolina\nFor this part of the analysis, we will focus on counties in North Carolina. We will use the data sets election_nc and county_map_data.\n\nVisualize the distribution of the response variable inperson_pct and calculate appropriate summary statistics. Use the visualization and summary statistics to describe the distribution. Include an informative title and axis labels on the plot.\nLet‚Äôs view the data in another way. Use the code below to make a map of North Carolina with the color of each county filled in based on the percentage of votes cast in-person in the 2020 election. Fill in title and axis labels.\nThen use the plot answer the following:\n\nWhat are 2 - 3 observations you have from the plot?\nWhat is a feature that is apparent in the map that wasn‚Äôt apparent from the histogram in the previous exercise? What is a feature that is apparent in the histogram that is not apparent in the map?\n\n\n\nelection_map_data &lt;- left_join(election_nc, county_map_data)\n\nggplot() +\n  geom_polygon(data = county_map_data,\n    mapping = aes(x = long, y = lat, group = group),\n    fill = \"lightgray\", color = \"white\"\n    ) +\n  geom_polygon(data = election_map_data, \n    mapping = aes(x = long, y = lat, group = group,\n    fill = inperson_pct)\n    ) +\n  labs(\n    x = \"___\",\n    y = \"___\",\n    fill = \"___\",\n    title = \"___\"\n  ) +\n  scale_fill_viridis_c(labels = label_percent(scale = 1)) +\n  coord_quickmap()\n\n\nCreate a visualization of the relationship between inperson_pct and pctTrump_2016. Use the visualization to describe the relationship between the two variables.\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you haven‚Äôt yet done so, now is a good time to render your document and commit (with a meaningful commit message) and push all updates.\n\n\n\nWe can use a linear regression model to better quantify the relationship between the variables.\n\nFit the linear model to understand variability in the percent of in-person votes based on the percent of votes for Trump in the 2016 election. Neatly display the model output with 3 digits.\nWrite the regression equation using mathematical notation.\n\nNow let‚Äôs use the model coefficients to describe the relationship.\n\nInterpret the slope. The interpretation should be written in a way that is meaningful in the context of the data.\nDoes it make sense to interpret the intercept? If so, write the interpretation in the context of the data. Otherwise, briefly explain why not.\n\nIf the linear model is a good fit to these data, there should be no structure left in the residuals and the residuals should have constant variance. Augment the data with the model to obtain the residuals and predicted values for each observation, and call the augmented data frame nc_election_aug (You will use this name in Exercise 8). Then, make a plot of the residuals vs.¬†the fitted values, and based on this plot, and provide a brief explanation for whether these two conditions are met. Hint: Zoom out on the plot by extending the limits of the y-axis.\n\n\n\n\n\n\n\nWarning\n\n\n\nNow is a good time to render your document again if you haven‚Äôt done so recently and commit (with a meaningful commit message) and push all updates.\n\n\n\nWe might also be interested in our observations being independent, particularly if we are to use these data for inference. To evaluate whether the independence condition is met, we will examine a map of the counties in North Carolina with the color filled based on the value of the residuals.\n\nBriefly explain why we may want to view the residuals on a map to assess independence.\nBriefly explain what pattern (if any) we would expect to observe on the map if the independence condition is satisfied.\n\nFill in the name of your model in the code below to calculate the residuals and add them to election_map_data. Then, a map with the color of each county filled in based on the value of the residual. Hint: Start with the code from Exercise 2.\nIs the independence condition satisfied? Briefly explain based on what you observe from the plot.\n\nnc_election_aug &lt;- nc_election_aug %&gt;% \n  bind_cols(fips = election_nc$fips)\n\nelection_map_data &lt;- left_join(election_map_data, nc_election_aug)\n\n\n\n\n\n\n\n\nWarning\n\n\n\nBefore moving on to the next part, make sure you render your document and commit (with a meaningful commit message) and push all updates.\n\n\n\n\nPart 2: Inference for the U.S.\nTo get a better understanding of the trend across the entire United States, we analyze data from a random sample of 200 counties. This data is in the election_sample data frame. Because these counties were randomly selected out of the 3,006 counties in the United States, we can reasonably treat the counties as independent observations.\n\nFit the linear model to these sample data to understand variability in the percent of in-person votes based on the percent of votes for Trump in the 2016 election. Neatly display the model output with 3 digits.\nConduct a hypothesis test for the slope using a permutation test. In your response, state the null and alternative hypotheses in words, and state the conclusion in the context of the data.\nNext, construct a 95% confidence interval for the slope using bootstrapping. Interpret the confidence interval in the context of the data.\nComment on whether the hypothesis test and confidence interval support the general consensus that Republican voters were more likely to vote in-person in the 2020 election? A brief explanation is sufficient but it should be based on your conclusions from Exercises 10 and 11.\n\n\n\n\n\n\n\nWarning\n\n\n\nBefore submitting, make sure you render your document and commit (with a meaningful commit message) and push all updates."
  },
  {
    "objectID": "hw/hw-1.html#submission",
    "href": "hw/hw-1.html#submission",
    "title": "HW 1 - In-person voting trends",
    "section": "Submission",
    "text": "Submission\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nRemember ‚Äì you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials ‚û°Ô∏è Duke NetID and log in using your NetID credentials.\nClick on your STA 210 course.\nClick on the assignment, and you‚Äôll be prompted to submit it.\nMark the pages associated with each exercise. All of the pages of your lab should be associated with at least one question (i.e., should be ‚Äúchecked‚Äù).\nSelect the first page of your PDF submission to be associated with the ‚ÄúWorkflow & formatting‚Äù section."
  },
  {
    "objectID": "hw/hw-1.html#grading",
    "href": "hw/hw-1.html#grading",
    "title": "HW 1 - In-person voting trends",
    "section": "Grading",
    "text": "Grading\nTotal points available: 50 points.\n\n\n\nComponent\nPoints\n\n\n\n\nEx 1 - 10\n45\n\n\nWorkflow & formatting\n51"
  },
  {
    "objectID": "hw/hw-1.html#footnotes",
    "href": "hw/hw-1.html#footnotes",
    "title": "HW 1 - In-person voting trends",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe ‚ÄúWorkflow & formatting‚Äù grade is to assess the reproducible workflow. This includes having at least 3 informative commit messages and updating the name and date in the YAML.‚Ü©Ô∏é"
  },
  {
    "objectID": "exams/exam-2.html",
    "href": "exams/exam-2.html",
    "title": "Exam 2",
    "section": "",
    "text": "Exam 1 will be released on Friday, Feb 25 at 9 am ET and must be completed by Mon, Feb 28 at 11:59 pm.\nThe exam will consist of two parts:\n\nPart 1 - Conceptual: Multiple choice questions on Sakai test and quizzes. This portion may only be submitted one time. Go here to complete Part 1 of the exam.\nPart 2 - Applied: Data analysis in RStudio and submitted in Gradescope (like a usual lab and homework). Go to the GitHub organization for the course and find the exam-2- repo to complete Part 2 of your exam. Add your answers to the exam-2.qmd file in your repo.\n\nBoth portions must be completed and submitted by Mon, Feb 28 at 11:59 pm. Late work will only be accepted in the case of of extenuating circumstances and notification from your academic dean.\nüçÄ Good luck! üçÄ\n\n\n\nBy taking this exam, you pledge to uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised.\n\n\n\n\n\nThis is an individual assignment. Everything in your repository and on Sakai is for your eyes only.\nYou may not collaborate or communicate anything about this exam to anyone except the instructor and the head TA (Rick Presman). For example, you may not communicate with other students, other TAs, or post/solicit help on the internet, email or via any other method of communication.\nThe exam is open-book, open-note, so you may use any materials from class as you take the exam.\nOnly head TA and professor office hours will be held during the exam period.\nYou may not email the TAs questions about the exam.\nIf you have questions, direct message the professor or the head TA (Rick Presman) on Slack or post on Sakai Conversations for ‚ÄúInstructors in this site‚Äù only or attend my office hours (Monday, 10:30 am - 11:30 am).\n\n\n\n\n\nPart 1 - Conceptual: The answers to the multiple choice/short answer questions should be submitted under Test & Quizzes in Sakai.\nPart 2 - Applied: The PDF document for the data analysis portion must be uploaded to Gradescope.\n\nYou must submit a PDF to Gradescope that corresponds to the .qmd file on your GitHub repository in order to receive credit for this portion of the exam.\nYou must upload a PDF, not HTML. Any non-PDF submissions will not be graded.\nMark the pages associated with each question. If any answer for a question spans multiple pages, mark all associated pages.\nMake sure to associate the ‚ÄúWorkflow & formatting‚Äù section with the first page.\nFailure to mark the pages in Gradescope will result in point deductions. Any pages that are not marked will not be graded.\nMake sure that your uploaded PDF document matches your .qmd and the PDF in your GitHub repository exactly. Points will be deducted for documents that are not reproducible."
  },
  {
    "objectID": "exams/exam-2.html#overview",
    "href": "exams/exam-2.html#overview",
    "title": "Exam 2",
    "section": "",
    "text": "Exam 1 will be released on Friday, Feb 25 at 9 am ET and must be completed by Mon, Feb 28 at 11:59 pm.\nThe exam will consist of two parts:\n\nPart 1 - Conceptual: Multiple choice questions on Sakai test and quizzes. This portion may only be submitted one time. Go here to complete Part 1 of the exam.\nPart 2 - Applied: Data analysis in RStudio and submitted in Gradescope (like a usual lab and homework). Go to the GitHub organization for the course and find the exam-2- repo to complete Part 2 of your exam. Add your answers to the exam-2.qmd file in your repo.\n\nBoth portions must be completed and submitted by Mon, Feb 28 at 11:59 pm. Late work will only be accepted in the case of of extenuating circumstances and notification from your academic dean.\nüçÄ Good luck! üçÄ"
  },
  {
    "objectID": "exams/exam-2.html#academic-integrity",
    "href": "exams/exam-2.html#academic-integrity",
    "title": "Exam 2",
    "section": "",
    "text": "By taking this exam, you pledge to uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised."
  },
  {
    "objectID": "exams/exam-2.html#rules-notes",
    "href": "exams/exam-2.html#rules-notes",
    "title": "Exam 2",
    "section": "",
    "text": "This is an individual assignment. Everything in your repository and on Sakai is for your eyes only.\nYou may not collaborate or communicate anything about this exam to anyone except the instructor and the head TA (Rick Presman). For example, you may not communicate with other students, other TAs, or post/solicit help on the internet, email or via any other method of communication.\nThe exam is open-book, open-note, so you may use any materials from class as you take the exam.\nOnly head TA and professor office hours will be held during the exam period.\nYou may not email the TAs questions about the exam.\nIf you have questions, direct message the professor or the head TA (Rick Presman) on Slack or post on Sakai Conversations for ‚ÄúInstructors in this site‚Äù only or attend my office hours (Monday, 10:30 am - 11:30 am)."
  },
  {
    "objectID": "exams/exam-2.html#submission",
    "href": "exams/exam-2.html#submission",
    "title": "Exam 2",
    "section": "",
    "text": "Part 1 - Conceptual: The answers to the multiple choice/short answer questions should be submitted under Test & Quizzes in Sakai.\nPart 2 - Applied: The PDF document for the data analysis portion must be uploaded to Gradescope.\n\nYou must submit a PDF to Gradescope that corresponds to the .qmd file on your GitHub repository in order to receive credit for this portion of the exam.\nYou must upload a PDF, not HTML. Any non-PDF submissions will not be graded.\nMark the pages associated with each question. If any answer for a question spans multiple pages, mark all associated pages.\nMake sure to associate the ‚ÄúWorkflow & formatting‚Äù section with the first page.\nFailure to mark the pages in Gradescope will result in point deductions. Any pages that are not marked will not be graded.\nMake sure that your uploaded PDF document matches your .qmd and the PDF in your GitHub repository exactly. Points will be deducted for documents that are not reproducible."
  },
  {
    "objectID": "course-team.html",
    "href": "course-team.html",
    "title": "Teaching team",
    "section": "",
    "text": "Dr.¬†Mine √áetinkaya-Rundel (she/her) is Professor of the Practice and Director of Undergraduate Studies at the Department of Statistical Science at Duke University. Mine‚Äôs work focuses on innovation in statistics and data science pedagogy, with an emphasis on computing, reproducible research, student-centered learning, and open-source education as well as pedagogical approaches for enhancing retention of women and under-represented minorities in STEM. Mine also works with RStudio as a Developer Educator.\n\n\n\nOffice hours\nLocation\n\n\n\n\nMondays 10:30 am - 11:30 am\nZoom\n\n\nThursdays 11:00 am - 12:00 pm\nOld Chem 213\n\n\n\nIf these times don‚Äôt work for you or you‚Äôd like to schedule a one-on-one meeting, you can do so at bit.ly/meet-mine.",
    "crumbs": [
      "Course information",
      "Teaching team"
    ]
  },
  {
    "objectID": "course-team.html#instructor",
    "href": "course-team.html#instructor",
    "title": "Teaching team",
    "section": "",
    "text": "Dr.¬†Mine √áetinkaya-Rundel (she/her) is Professor of the Practice and Director of Undergraduate Studies at the Department of Statistical Science at Duke University. Mine‚Äôs work focuses on innovation in statistics and data science pedagogy, with an emphasis on computing, reproducible research, student-centered learning, and open-source education as well as pedagogical approaches for enhancing retention of women and under-represented minorities in STEM. Mine also works with RStudio as a Developer Educator.\n\n\n\nOffice hours\nLocation\n\n\n\n\nMondays 10:30 am - 11:30 am\nZoom\n\n\nThursdays 11:00 am - 12:00 pm\nOld Chem 213\n\n\n\nIf these times don‚Äôt work for you or you‚Äôd like to schedule a one-on-one meeting, you can do so at bit.ly/meet-mine.",
    "crumbs": [
      "Course information",
      "Teaching team"
    ]
  },
  {
    "objectID": "course-team.html#teaching-assistants",
    "href": "course-team.html#teaching-assistants",
    "title": "Teaching team",
    "section": "Teaching assistants",
    "text": "Teaching assistants\n\n\n\n\nName\nOffice hours\nLocation\n\n\n\n\n\nMartha Aboagye\nThursday 7 - 9 pm\nZoom\n\n\n\nRichard Fremgen\nLead TA for Section 3 (5:15 pm)\nTues 7 - 9 pm\nZoom\n\n\n\nEmily Gentles\nLead TA for Section 1 (1:45pm)\nWednesday 1 - 3 pm\nOld Chem 203B (On Zoom until January 18)\n\n\n\nSara Mehta\nMon 2 - 4 pm\nZoom\n\n\n\nRick Presman\nHead TA\nLead TA for Section 2 (3:30pm)\nThursday 3:30 - 4:30 pm\nFri 9 - 10 am\nZoom\n\n\n\nShari Tian\nTue 8 - 10 am\nZoom\n\n\n\nAaditya Warrier\nMon 12pm - 1pm\nFri 1:30 - 2:30 pm\nZoom",
    "crumbs": [
      "Course information",
      "Teaching team"
    ]
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Course support",
    "section": "",
    "text": "Most of you will need help at some point and we want to make sure you can identify when that is without getting too frustrated and feel comfortable seeking help.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#lectures-and-labs",
    "href": "course-support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#office-hours",
    "href": "course-support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage each and every one of you to take advantage of this resource! Make a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of everyone‚Äôs office hours here.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#discussion-forum",
    "href": "course-support.html#discussion-forum",
    "title": "Course support",
    "section": "Discussion forum",
    "text": "Discussion forum\nHave a question that can‚Äôt wait for office hours? Prefer to write out your question in detail rather than asking in person? The online discussion forum is the best venue for these! We will use Conversations as the online discussion forum. There is a chance another student has already asked a similar question, so please check the other posts on Ed Discussion before adding a new question. If you know the answer to a question that is posted, I encourage you to respond!",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#email",
    "href": "course-support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nPlease refrain from emailing any course content questions (those should go Conversations), and only use email for questions about personal matters that may not be appropriate for the public course forum (e.g., illness, accommodations, etc.). For such matters, you may email Dr.¬†Mine √áetinkaya-Rundel at mc301@duke.edu.\nIf there is a question that‚Äôs not appropriate for the public forum, you are welcome to email me directly. If you email me, please include ‚ÄúSTA 210‚Äù in the subject line. Barring extenuating circumstances, I will respond to STA 210 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#academic-support",
    "href": "course-support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times you may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. ARC services are available free to any Duke undergraduate student, in any year, studying in any discipline. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact theARC@duke.edu, 919-684-5917.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#mental-health-and-wellness",
    "href": "course-support.html#mental-health-and-wellness",
    "title": "Course support",
    "section": "Mental health and wellness",
    "text": "Mental health and wellness\nStudent mental health and wellness is of primary importance at Duke, and the university offers resources to support students in managing daily stress and self-care. Duke offers several resources for students to seek assistance on coursework and to nurture daily habits that support overall well-being, some of which are listed below:\n\nThe Academic Resource Center: (919) 684-5917, theARC@duke.edu, or arc.duke.edu,\nDuWell: (919) 681-8421, duwell@studentaffairs.duke.edu, or studentaffairs.duke.edu/duwell\n\nIf your mental health concerns and/or stressful events negatively affect your daily emotional state, academic performance, or ability to participate in your daily activities, many resources are available to help you through difficult times. Duke encourages all students to access these resources.\n\nDukeReach. Provides comprehensive outreach services to identify and support students in managing all aspects of well-being. If you have concerns about a student‚Äôs behavior or health visit the website for resources and assistance. studentaffairs.duke.edu/dukereach\nCounseling and Psychological Services (CAPS). CAPS helps Duke Students enhance strengths and develop abilities to successfully live, grow and learn in their personal and academic lives. CAPS recognizes that we are living in unprecedented times and that the changes, challenges and stressors brought on by the COVID-19 pandemic have impacted everyone, often in ways that are tax our well-being. CAPS offers many services to Duke undergraduate students, including brief individual and group counseling, couples counseling and more. CAPS staff also provides outreach to student groups, particularly programs supportive of at-risk populations, on a wide range of issues impacting them in various aspects of campus life. CAPS provides services to students via Telehealth. To initiate services, you can contact their front desk at 919-660-1000. studentaffairs.duke.edu/caps\nBlue Devils Care. A convenient and cost-effective way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling. bluedevilscare.duke.edu\nTwo-Click Support. Duke Student Government and DukeReach partnership that connects students to help in just two clicks. bit.ly/TwoClickSupport\nWellTrack. Sign up for WellTrack at app.welltrack.com.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#technology-accommodations",
    "href": "course-support.html#technology-accommodations",
    "title": "Course support",
    "section": "Technology accommodations",
    "text": "Technology accommodations\nStudents with demonstrated high financial need who have limited access to computers may request assistance in the form of loaner laptops. For technology assistance requests, please go here. Please note that supplies are limited.\nNote that we will be using Duke‚Äôs computational resources in this course. These resources are freely available to you. As long as your computer can connect to the internet and open a browser window, you can perform the necessary computing for this course. All software we use is open-source and/or freely available.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#course-materials-costs",
    "href": "course-support.html#course-materials-costs",
    "title": "Course support",
    "section": "Course materials costs",
    "text": "Course materials costs\nThere are no costs associated with this course. All readings will come from freely available, open resources (open-source textbooks, journal articles, etc.).",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#assistance-with-zoom-or-sakai",
    "href": "course-support.html#assistance-with-zoom-or-sakai",
    "title": "Course support",
    "section": "Assistance with Zoom or Sakai",
    "text": "Assistance with Zoom or Sakai\nFor technical help with Sakai or Zoom, contact the Duke OIT Service Desk at oit.duke.edu/help. You can also access the self-service help documentation for Zoom here and for Sakai here.\nNote that we will be making minimal use of Sakai in this course (primarily for announcements and grade book). All assignment submission and discussion will take place on GitHub instead.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "RStudio containers\nüîó on Duke Container Manager\n\n\nCourse GitHub organization\nüîó on GitHub\n\n\nDiscussion forum\nüîó on Sakai\n\n\nLecture streaming and recordings\nüîó on Panopto\n\n\nGradebook\nüîó on Sakai\n\n\nVirtual meetings\nüîó on Sakai",
    "crumbs": [
      "Course information",
      "Useful links"
    ]
  },
  {
    "objectID": "computing-troubleshooting.html",
    "href": "computing-troubleshooting.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If you‚Äôre having difficulty launching an RStudio session from your reserved container, go to status.oit.duke.edu and scroll down to Teaching and Learning Tools. Under this heading you‚Äôll find an entry called Container Manager (CMGR Coursework Containers).\n\nIf the status shows something other than Operational, this means there is a known incident with the containers. Check back later to see if it‚Äôs been resolved. If there‚Äôs a deadline coming up soon, post on the course forum to let us know that there‚Äôs an issue. We can look into how quickly it might get resolved and decide on what to do about the deadline accordingly. Note: We don‚Äôt anticipate this to happen regularly, the systems are Operational a huge majority of the time!\nIf the status shows Operational, this means the system is expected to be working. Check your internet connection, if need be, restart your computer to ensure a fresh new connection. If your issue persists, post on the course forum with details on what you‚Äôve tried and the errors you see (including verbatim errors and/or screenshots).\nEither way you can also fill out the form here, which will notify our the R TA for the department as well as our undergraduate coordinator. They‚Äôll be able to help diagnose the issue.",
    "crumbs": [
      "Computing",
      "Troubleshooting"
    ]
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "To access computing resources for the introductory data science courses offered by the Duke University Department of Statistical Science, go to the Duke Container Manager website, cmgr.oit.duke.edu/containers.\nIf this is your first time accessing the containers, click on reserve STA210 on the Reservations available menu on the right. You only need to do this once, and when you do, you‚Äôll see this container moved to the My reservations menu on the left.\nNext, click on STA210 under My reservations to access the RStudio instance you‚Äôll use for the course.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  },
  {
    "objectID": "computing-pipelines.html",
    "href": "computing-pipelines.html",
    "title": "Pipelines",
    "section": "",
    "text": "library(palmerpenguins)\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.3.1 ‚îÄ‚îÄ\n\n\n‚úì ggplot2 3.3.5     ‚úì purrr   0.3.4\n‚úì tibble  3.1.6     ‚úì dplyr   1.0.7\n‚úì tidyr   1.1.4     ‚úì stringr 1.4.0\n‚úì readr   2.1.1     ‚úì forcats 0.5.1\n\n\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\nlibrary(tidymodels)\n\nRegistered S3 method overwritten by 'tune':\n  method                   from   \n  required_pkgs.model_spec parsnip\n\n\n‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidymodels 0.1.4 ‚îÄ‚îÄ\n\n\n‚úì broom        0.7.10         ‚úì rsample      0.1.1     \n‚úì dials        0.0.10         ‚úì tune         0.1.6     \n‚úì infer        1.0.1.9000     ‚úì workflows    0.2.4     \n‚úì modeldata    0.1.1          ‚úì workflowsets 0.1.0     \n‚úì parsnip      0.1.7          ‚úì yardstick    0.0.9     \n‚úì recipes      0.2.0          \n\n\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidymodels_conflicts() ‚îÄ‚îÄ\nx scales::discard() masks purrr::discard()\nx dplyr::filter()   masks stats::filter()\nx recipes::fixed()  masks stringr::fixed()\nx dplyr::lag()      masks stats::lag()\nx yardstick::spec() masks readr::spec()\nx recipes::step()   masks stats::step()\n‚Ä¢ Search for functions across packages at https://www.tidymodels.org/find/\n\nlibrary(knitr)"
  },
  {
    "objectID": "computing-pipelines.html#simple-linear-regression",
    "href": "computing-pipelines.html#simple-linear-regression",
    "title": "Pipelines",
    "section": "Simple linear regression",
    "text": "Simple linear regression\n\nModel fitting\nFit model:\n\npenguins_fit &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  fit(body_mass_g ~ flipper_length_mm, data = penguins)\n\nTidy model output:\n\ntidy(penguins_fit)\n\n# A tibble: 2 √ó 5\n  term              estimate std.error statistic   p.value\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)        -5781.     306.       -18.9 5.59e- 55\n2 flipper_length_mm     49.7      1.52      32.7 4.37e-107\n\n\nFormat model output as table:\n\ntidy(penguins_fit) %&gt;%\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-5780.831\n305.815\n-18.903\n0\n\n\nflipper_length_mm\n49.686\n1.518\n32.722\n0\n\n\n\n\n\nAugment data with model:\n\naugment(penguins_fit$fit)\n\n# A tibble: 342 √ó 9\n   .rownames body_mass_g flipper_length_‚Ä¶ .fitted  .resid    .hat .sigma .cooksd\n   &lt;chr&gt;           &lt;int&gt;            &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1 1                3750              181   3212.  538.   0.00881   394. 8.34e-3\n 2 2                3800              186   3461.  339.   0.00622   394. 2.33e-3\n 3 3                3250              195   3908. -658.   0.00344   393. 4.83e-3\n 4 5                3450              193   3808. -358.   0.00385   394. 1.60e-3\n 5 6                3650              190   3659.   -9.43 0.00469   395. 1.35e-6\n 6 7                3625              181   3212.  413.   0.00881   394. 4.91e-3\n 7 8                4675              195   3908.  767.   0.00344   393. 6.56e-3\n 8 9                3475              193   3808. -333.   0.00385   394. 1.39e-3\n 9 10               4250              190   3659.  591.   0.00469   394. 5.31e-3\n10 11               3300              186   3461. -161.   0.00622   395. 5.23e-4\n# ‚Ä¶ with 332 more rows, and 1 more variable: .std.resid &lt;dbl&gt;\n\n\n\n\nStatistical inference"
  },
  {
    "objectID": "course-faq.html",
    "href": "course-faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Go to your Files tab, check the box next to the file you want to download, then click on the blue gear icon on the Files tab to reveal the drop down menu, and select Export‚Ä¶ If you have selected multiple files to export, RStudio will zip them up into a single zip file for you. If you‚Äôve selected just a single file, it will only download that. The downloaded file will go to wherever files you download off the internet goes on your computer (usually your Downloads folder).",
    "crumbs": [
      "Course information",
      "FAQ"
    ]
  },
  {
    "objectID": "course-faq.html#how-do-i-export-my-assignment-pdf-from-rstudio-to-upload-to-gradescope",
    "href": "course-faq.html#how-do-i-export-my-assignment-pdf-from-rstudio-to-upload-to-gradescope",
    "title": "FAQ",
    "section": "",
    "text": "Go to your Files tab, check the box next to the file you want to download, then click on the blue gear icon on the Files tab to reveal the drop down menu, and select Export‚Ä¶ If you have selected multiple files to export, RStudio will zip them up into a single zip file for you. If you‚Äôve selected just a single file, it will only download that. The downloaded file will go to wherever files you download off the internet goes on your computer (usually your Downloads folder).",
    "crumbs": [
      "Course information",
      "FAQ"
    ]
  },
  {
    "objectID": "course-faq.html#how-can-i-submit-my-assignment-to-gradescope",
    "href": "course-faq.html#how-can-i-submit-my-assignment-to-gradescope",
    "title": "FAQ",
    "section": "How can I submit my assignment to Gradescope?",
    "text": "How can I submit my assignment to Gradescope?\nThe instructions for submitting your assignment to Gradescope can be found here. In a nutshell, you‚Äôll upload your PDF and them mark the page(s) where each question can be found. It‚Äôs OK if a question spans multiple pages, just mark them all. It‚Äôs also OK if a page includes multiple questions.",
    "crumbs": [
      "Course information",
      "FAQ"
    ]
  },
  {
    "objectID": "course-faq.html#can-i-use-a-local-install-of-r-and-rstudio-instead-of-using-the-rstudio-containers",
    "href": "course-faq.html#can-i-use-a-local-install-of-r-and-rstudio-instead-of-using-the-rstudio-containers",
    "title": "FAQ",
    "section": "Can I use a local install of R and RStudio instead of using the RStudio containers?",
    "text": "Can I use a local install of R and RStudio instead of using the RStudio containers?\nThe short answer is, I‚Äôd rather you didn‚Äôt, to save yourself some headache. But, the long answer is, sure! But you will need to install a specific versions of R and RStudio for everything to work as expected. You will also need to install the R packages we‚Äôre using as well as have Git installed on your computer. These are not extremely challenging things to get right, but they are not trivial either, particularly on certain operating systems. Myself and the TAs are always happy to provide help with any computational questions when you‚Äôre working in the containers we have provided for you. If you‚Äôre working on your local setup, we can‚Äôt guarantee being able to resolve your issues, though we‚Äôre happy to try.\nIf you want to take this path, here is what you need to do:\n\nDownload and install R 4.1.2: https://cran.r-project.org/\nDownload and install a daily build of RStudio: https://dailies.rstudio.com/\nInstall Quarto CLI: https://quarto.org/docs/getting-started/installation.html\nInstall Git: https://happygitwithr.com/install-git.html\nInstall any necessary packages with install.packages(\"___\")\n\nAnd I‚Äôd like to reiterate again that successful installation of these software is not a learning goal of this course. So if any of this seems tedious or intimidating in any way, just use the computing environment we have set up for you. More on that here.",
    "crumbs": [
      "Course information",
      "FAQ"
    ]
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "STA 210: Regression Analysis",
    "section": "",
    "text": "Learn approaches for analyzing multivariate data sets, emphasizing analysis of variance, linear regression, and logistic regression. Learn techniques for checking the appropriateness of proposed models, such as residual analyses and case influence diagnostics, and techniques for selecting models. Gain experience dealing with the challenges that arise in practice through assignments that utilize real-world data. This class emphasizes data analysis over mathematical theory.",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Click here to download a PDF copy of the syllabus.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-info",
    "href": "course-syllabus.html#course-info",
    "title": "Syllabus",
    "section": "Course info",
    "text": "Course info\n\n\n\n\n\n\n\n\n\n\nDay\nTime\nLocation\n\n\n\n\nLectures\nTue & Thu\n1:45 pm - 3:00 pm\nReuben-Cooke Building 130\n\n\nSection 1\nMon\n1:45 pm - 3:00 pm\nPerkins LINK 087 (Classroom 3)\n\n\nSection 2\nMon\n3:30 pm - 4:45 pm\nOld Chemistry 003\n\n\nSection 3\nMon\n5:15 pm - 6:30 pm\nSocial Sciences 311",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#learning-objectives",
    "href": "course-syllabus.html#learning-objectives",
    "title": "Syllabus",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of the semester, you will be able to‚Ä¶\n\nanalyze real-world data to answer questions about multivariable relationships.\nfit and evaluate linear and logistic regression models.\nassess whether a proposed model is appropriate and describe its limitations.\nuse Quarto to write reproducible reports and GitHub for version control and collaboration.\ncommunicate results from statistical analyses to a general audience.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#community",
    "href": "course-syllabus.html#community",
    "title": "Syllabus",
    "section": "Community",
    "text": "Community\n\nDuke Community Standard\nAs a student in this course, you have agreed to uphold the Duke Community Standard as well as the practices specific to this course.\n\n\n\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students‚Äô learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke‚Äôs Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don‚Äôt hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website at sta210-s22.github.io/website.\nI will regularly send course announcements via email and Sakai, make sure to check one or the other of these regularly. If an announcement is sent Monday through Thursday, I will assume that you have read the announcement by the next day. If an announcement is sent on a Friday or over the weekend, I will assume that you have read it by Monday.\n\n\nWhere to get help\n\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. Please use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the course forum Conversations. There is a chance another student has already asked a similar question, so please check the other posts in Conversations before adding a new question. If you know the answer to a question posted in the discussion forum, I encourage you to respond!\nEmails should be reserved for questions not appropriate for the public forum. If you email me, please include ‚ÄúSTA 210‚Äù in the subject line. Barring extenuating circumstances, I will respond to STA 210 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.\n\nCheck out the Support page for more resources.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#textbooks",
    "href": "course-syllabus.html#textbooks",
    "title": "Syllabus",
    "section": "Textbooks",
    "text": "Textbooks\nWhile there is no official textbook for the course, we will be assigning readings from the following textbooks.\n\nR for Data Science by Garret Grolemund and Hadley Wickham\nIntroduction to Modern Statistics by Mine √áetinkaya-Rundel and Johanna Hardin\nTidy modeling with R by Max Kuhn and Julia Silge\nBeyond Multiple Linear Regression by Paul Roback and Julie Legler",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#lectures-and-labs",
    "href": "course-syllabus.html#lectures-and-labs",
    "title": "Syllabus",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nThe goal of both the lectures and the labs is for them to be as interactive as possible. My role as instructor is to introduce you new tools and techniques, but it is up to you to take them and make use of them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities throughout each lecture and lab. You are expected to attend all lecture and lab sessions and meaningfully contribute to in-class exercises and discussion. Additionally, some lectures will feature application exercises that will be graded. In addition to application exercises will be periodic activities help build a learning community. These will be short, fun activities that will help everyone in the class connect throughout the semester.\nYou are expected to bring a laptop to each class so that you can take part in the in-class exercises. Please make sure your laptop is fully charged before you come to class as the number of outlets in the classroom will not be sufficient to accommodate everyone. More information on loaner laptops can be found here.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#teams",
    "href": "course-syllabus.html#teams",
    "title": "Syllabus",
    "section": "Teams",
    "text": "Teams\nYou will be assigned to a team at the beginning of the semester. You are encouraged to sit with your teammates in lecture and you will also work with them in the lab sessions. All team members are expected to contribute equally to the completion of the labs and project and you will be asked to evaluate your team members throughout the semester. Failure to adequately contribute to an assignment will result in a penalty to your mark relative to the team‚Äôs overall mark.\nYou are expected to make use of the provided GitHub repository as their central collaborative platform. Commits to this repository will be used as a metric (one of several) of each team member‚Äôs relative contribution for each project.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#assessment",
    "href": "course-syllabus.html#assessment",
    "title": "Syllabus",
    "section": "Assessment",
    "text": "Assessment\nAssessment for the course is comprised of six components: application exercises, homework assignments, labs, exams, projects, and teamwork.\n\nApplication exercises\nParts of some lectures will be dedicated to working on Application Exercises (AEs). These exercises which give you an opportunity to practice apply the statistical concepts and code introduced in the readings and lectures. These AEs are due within three days of the corresponding lecture period. Specifically, AEs from Tuesday lectures are due Friday by 11:59 pm ET, and AEs from Thursday lectures are due Sunday by 11:59 pm ET.\nBecause these AEs are for practice, they will be graded based on completion, i.e., a good-faith effort has been made in attempting all parts. Successful on-time completion of at least 80% of AEs will result in full credit for AEs in the final course grade.\n\n\nLabs\nIn labs, you will apply the concepts discussed in lecture to various data analysis scenarios, with a focus on the computation. Most lab assignments will be completed in teams, and all team members are expected to contribute equally to the completion of each assignment. You are expected to use the team‚Äôs GitHub repository on the course‚Äôs GitHub organization as the central platform for collaboration. Commits to this repository will be used as a metric of each team member‚Äôs relative contribution for each lab, and there will be periodic peer evaluation on the team collaboration. Lab assignments will be completed using Quarto, correspond to an appropriate GitHub repository, and submitted for grading in Gradescope.\nThe lowest lab grade will be dropped at the end of the semester.\n\n\nHomework\nIn homework, you will apply what you‚Äôve learned during lecture and lab to complete data analysis tasks. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Similar to lab assignments, homework must be typed up using Quarto and GitHub and submitted as a PDF in Gradescope.\nOne homework assignment will be dedicated to a statistics experience. The statistics experience is an opportunity to engage with statistics and data science outside of the classroom through podcasts, books, seminars, data analysis competitions, and other activities. As you complete these experiences, the goal is to consider how the material you‚Äôre learning in the course connects with society more broadly.\nThe lowest homework grade will be dropped at the end of the semester.\n\n\nExams\nThere will be three, take-home, open-note exams. Through these exams you have the opportunity to demonstrate what you‚Äôve learned in the course thus far. The exams will focus on the conceptual understanding of the content, and they may also include small analysis and computational tasks. The content of the exam will be related to the content in the prepare, practice, and perform assignments. More detail about the exams will be given during the semester.\n\n\nProject\nThe purpose of the project is to apply what you‚Äôve learned throughout the semester to analyze an interesting, data-driven research question. The project will be completed with your lab teams, and each team will present their work in video and in writing during the final exam period. More information about the project will be provided during the semester.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#grading",
    "href": "course-syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\nCategory\nPercentage\n\n\n\n\nApplication exercises\n3%\n\n\nHomework\n35% (7% x 5)\n\n\nProject\n15%\n\n\nLab\n14% (2.33% x 6)\n\n\nExam 01\n10%\n\n\nExam 02\n10%\n\n\nExam 03\n10%\n\n\nTeamwork\n3%\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n&gt;= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n&lt; 60",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#five-tips-for-success",
    "href": "course-syllabus.html#five-tips-for-success",
    "title": "Syllabus",
    "section": "Five tips for success",
    "text": "Five tips for success\nYour success on this course depends very much on you and the effort you put into it. The course has been organized so that the burden of learning is on you. Your TAs and I will help you be providing you with materials and answering questions and setting a pace, but for this to work you must do the following:\n\nComplete all the preparation work before class.\nAsk questions. As often as you can. In class, out of class. Ask me, ask the TAs, ask your friends, ask the person sitting next to you. This will help you more than anything else. If you get a question wrong on an assessment, ask us why. If you‚Äôre not sure about the homework, ask. If you hear something on the news that sounds related to what we discussed, ask. If the reading is confusing, ask.\nDo the readings.\nDo the homework and lab.The earlier you start, the better. It‚Äôs not enough to just mechanically plow through the exercises. You should ask yourself how these exercises relate to earlier material, and imagine how they might be changed (to make questions for an exam, for example.)\nDon‚Äôt procrastinate. If something is confusing to you in Week 2, Week 3 will become more confusing, Week 4 even worse, and eventually you won‚Äôt know where to begin asking questions. Don‚Äôt let the week end with unanswered questions. But if you find yourself falling behind and not knowing where to begin asking, come to office hours, and let me help you identify a good (re)starting point.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-policies",
    "href": "course-syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course policies",
    "text": "Course policies\n\nAcademic integrity\nTL;DR: Don‚Äôt cheat!\nAll students must adhere to the Duke Community Standard (DCS): Duke University is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, and accountability. Citizens of this community commit to reflect upon these principles in all academic and non-academic endeavors, and to protect and promote a culture of integrity.\nTo uphold the Duke Community Standard:\nStudents affirm their commitment to uphold the values of the Duke University community by signing a pledge that states:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors;\nI will act if the Standard is compromised\n\nRegardless of course delivery format, it is your responsibility to understand and follow Duke policies regarding academic integrity, including doing one‚Äôs own work, following proper citation of sources, and adhering to guidance around group work projects. Ignoring these requirements is a violation of the Duke Community Standard. If you have any questions about how to follow these requirements, please contact Jeanna McCullers (jeanna.mccullers@duke.edu), Director of the Office of Student Conduct.\n\n\nCollaboration policy\nOnly work that is clearly assigned as team work should be completed collaboratively.\n\nThe homework assignments must be completed individually and you are welcomed to discuss the assignment with classmates at a high level (e.g., discuss what‚Äôs the best way for approaching a problem, what functions are useful for accomplishing a particular task, etc.). However you may not directly share answers to homework questions (including any code) with anyone other than myself and the teaching assistants.\nFor the projects, collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project across teams.\n\n\n\nPolicy on sharing and reusing code\nI am well aware that a huge volume of code is available on the web to solve any number of problems. Unless I explicitly tell you not to use something, the course‚Äôs policy is that you may make use of any online resources (e.g.¬†RStudio Community, StackOverflow) but you must explicitly cite where you obtained any code you directly use (or use as inspiration). Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. On individual assignments you may not directly share code with another student in this class, and on team assignments you may not directly share code with another team in this class.\n\n\nLate work policy\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback within a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline. Note that the lowest homework and lab assignment will be dropped to accommodate such circumstances.\n\nHomework and labs may be submitted up to 3 days late. There will be a 5% deduction for each 24-hour period the assignment is late.\nThere is no late work accepted for application exercises, since these are designed to help you prepare for labs and homework.\nThe late work policy for exams will be provided with the exam instructions.\nThe late work policy for the project will be provided with the project instructions.\n\n\n\nWaiver for extenuating circumstances\nIf there are circumstances that prevent you from completing a lab or homework assignment by the stated due date, you may email Dr.¬†√áetinkaya-Rundel and our head TA Rick Presman before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used for once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let Dr.¬†√áetinkaya-Rundel know if you need help contacting your academic dean.\n\n\nRegrade request policy\nRegrade requests must be submitted on Gradescope within a week of when an assignment is returned. Regrade requests will be considered if there was an error in the grade calculation or if you feel a correct answer was mistakenly marked as incorrect. Requests to dispute the number of points deducted for an incorrect response will not be considered. Note that by submitting a regrade request, the entire question will be graded which could potentially result in losing points.\nNo grades will be changed after the final project presentations.\n\n\nAttendance policy\nResponsibility for class attendance rests with individual students. Since regular and punctual class attendance is expected, students must accept the consequences of failure to attend. More details on Trinity attendance policies are available here.\nHowever, there may be many reasons why you cannot be in class on a given day, particularly with possible extra personal and academic stress and health concerns this semester. All course lectures will be recorded and available to enrolled students after class. If you miss a lecture, make sure to watch the recording and review the material before the next class session. Lab time is dedicated to working on your lab assignments and collaborating with your teammates on your project. If you miss a lab session, make sure to communicate with your team about how you can make up your contribution. Given the technologies we use in the course, this is straightforward to do asynchronously. If you know you‚Äôre going to miss a lab session and you‚Äôre feeling well enough to do so, notify your teammates ahead of time. Overall these policies are put in place to ensure communication between team members, respect for each others‚Äô time, and also to give you a safety net in the case of illness or other reasons that keep you away from attending class.\n\n\nAttendance policy related to COVID symptoms, exposure, or infection\nStudent health, safety, and well-being are the university‚Äôs top priorities. To help ensure your well-being and the well-being of those around you, please do not come to class if you have symptoms related to COVID-19, have had a known exposure to COVID-19, or have tested positive for COVID-19. If any of these situations apply to you, you must follow university guidance related to the ongoing COVID-19 pandemic and current health and safety protocols. If you are experiencing any COVID-19 symptoms, contact student health at 919-681-9355. To keep the university community as safe and healthy as possible, you will be expected to follow these guidelines. Please reach out to me and your academic dean as soon as possible if you need to quarantine or isolate so that we can discuss arrangements for your continued participation in class.\n\n\nInclement weather policy\nIn the event of inclement weather or other connectivity-related events that prohibit class attendance, I will notify you how we will make up missed course content and work. This might entail holding the class on Zoom synchronously or watching a recording of the class.\n\n\nPolicy on video recording course content\nAll lectures will be recorded and available on Panopto, so students should not need to create their own recordings of lectures. If you feel that you need record the lectures yourself, you must get permission from me ahead of time and these recordings should be used for personal study only, no for distribution. The full policy on recording of lectures falls under the Duke University Policy on Intellectual Property Rights, available at provost.duke.edu/sites/default/files/FHB_App_P.pdf. Unauthorized distribution is a cause for disciplinary action by the Judicial Board.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#learning-during-a-pandemic",
    "href": "course-syllabus.html#learning-during-a-pandemic",
    "title": "Syllabus",
    "section": "Learning during a pandemic",
    "text": "Learning during a pandemic\nI want to make sure that you learn everything you were hoping to learn from this class. If this requires flexibility, please don‚Äôt hesitate to ask.\n\nYou never owe me personal information about your health (mental or physical) but you‚Äôre always welcome to talk to me. If I can‚Äôt help, I likely know someone who can.\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded during this crisis.\n\nNote: If you‚Äôve read this far in the syllabus, email me a picture of your pet if you have one or your favourite meme!",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#important-dates",
    "href": "course-syllabus.html#important-dates",
    "title": "Syllabus",
    "section": "Important dates",
    "text": "Important dates\n\nJanuary 5: Classes begin (Monday meeting schedule)\nJanuary 6: Regular class meeting schedule begins\nJanuary 17: Martin Luther King, Jr.¬†Day holiday, no classes are held\nJanuary 19: Drop/add ends\nMarch 7-11: Spring recess, no classes are held\nMarch 23: Last day to withdraw with W\nApril 20: Classes end\nApril 21-24: Reading period\nApril 25-30: Final exams\n\nClick here for the full Duke academic calendar.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "exams/exam-1.html",
    "href": "exams/exam-1.html",
    "title": "Exam 1",
    "section": "",
    "text": "Exam 1 will be released on Friday, Feb 4 at 9 am ET and must be completed by Mon, Feb 7 at 11:59 pm.\nThe exam will consist of two parts:\n\nPart 1 - Conceptual: Multiple choice questions on Sakai test and quizzes. This portion may only be submitted one time. Go here to complete Part 1 of the exam.\nPart 2 - Applied: Data analysis in RStudio and submitted in Gradescope (like a usual lab and homework). Go to the GitHub organization for the course and find the exam-1- repo to complete Part 3 of your exam. Add your answers to the exam-1.qmd file in your repo.\n\nBoth portions must be completed and submitted by Mon, Feb 7 at 11:59 pm. Late work will only be accepted in the case of of extenuating circumstances and notification from your academic dean.\nüçÄ Good luck! üçÄ\n\n\n\nBy taking this exam, you pledge to uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised.\n\n\n\n\n\nThis is an individual assignment. Everything in your repository and on Sakai is for your eyes only.\nYou may not collaborate or communicate anything about this exam to anyone except the instructor and the head TA (Rick Presman). For example, you may not communicate with other students, other TAs, or post/solicit help on the internet, email or via any other method of communication.\nThe exam is open-book, open-note, so you may use any materials from class as you take the exam.\nOnly head TA and professor office hours will be held during the exam period.\nYou may not email the TAs questions about the exam.\nIf you have questions, direct message the professor or the head TA (Rick Presman) on Slack or post on Sakai Conversations for ‚ÄúInstructors in this site‚Äù only or attend my office hours (Monday, 10:30 am - 11:30 am).\n\n\n\n\n\nPart 1 - Conceptual: The answers to the multiple choice/short answer questions should be submitted under Test & Quizzes in Sakai.\nPart 2 - Applied: The PDF document for the data analysis portion must be uploaded to Gradescope.\n\nYou must submit a PDF to Gradescope that corresponds to the .qmd file on your GitHub repository in order to receive credit for this portion of the exam.\nYou must upload a PDF, not HTML. Any non-PDF submissions will not be graded.\nMark the pages associated with each question. If any answer for a question spans multiple pages, mark all associated pages.\nMake sure to associate the ‚ÄúWorkflow & formatting‚Äù section with the first page.\nFailure to mark the pages in Gradescope will result in point deductions. Any pages that are not marked will not be graded.\nMake sure that your uploaded PDF document matches your .qmd and the PDF in your GitHub repository exactly. Points will be deducted for documents that are not reproducible."
  },
  {
    "objectID": "exams/exam-1.html#overview",
    "href": "exams/exam-1.html#overview",
    "title": "Exam 1",
    "section": "",
    "text": "Exam 1 will be released on Friday, Feb 4 at 9 am ET and must be completed by Mon, Feb 7 at 11:59 pm.\nThe exam will consist of two parts:\n\nPart 1 - Conceptual: Multiple choice questions on Sakai test and quizzes. This portion may only be submitted one time. Go here to complete Part 1 of the exam.\nPart 2 - Applied: Data analysis in RStudio and submitted in Gradescope (like a usual lab and homework). Go to the GitHub organization for the course and find the exam-1- repo to complete Part 3 of your exam. Add your answers to the exam-1.qmd file in your repo.\n\nBoth portions must be completed and submitted by Mon, Feb 7 at 11:59 pm. Late work will only be accepted in the case of of extenuating circumstances and notification from your academic dean.\nüçÄ Good luck! üçÄ"
  },
  {
    "objectID": "exams/exam-1.html#academic-integrity",
    "href": "exams/exam-1.html#academic-integrity",
    "title": "Exam 1",
    "section": "",
    "text": "By taking this exam, you pledge to uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised."
  },
  {
    "objectID": "exams/exam-1.html#rules-notes",
    "href": "exams/exam-1.html#rules-notes",
    "title": "Exam 1",
    "section": "",
    "text": "This is an individual assignment. Everything in your repository and on Sakai is for your eyes only.\nYou may not collaborate or communicate anything about this exam to anyone except the instructor and the head TA (Rick Presman). For example, you may not communicate with other students, other TAs, or post/solicit help on the internet, email or via any other method of communication.\nThe exam is open-book, open-note, so you may use any materials from class as you take the exam.\nOnly head TA and professor office hours will be held during the exam period.\nYou may not email the TAs questions about the exam.\nIf you have questions, direct message the professor or the head TA (Rick Presman) on Slack or post on Sakai Conversations for ‚ÄúInstructors in this site‚Äù only or attend my office hours (Monday, 10:30 am - 11:30 am)."
  },
  {
    "objectID": "exams/exam-1.html#submission",
    "href": "exams/exam-1.html#submission",
    "title": "Exam 1",
    "section": "",
    "text": "Part 1 - Conceptual: The answers to the multiple choice/short answer questions should be submitted under Test & Quizzes in Sakai.\nPart 2 - Applied: The PDF document for the data analysis portion must be uploaded to Gradescope.\n\nYou must submit a PDF to Gradescope that corresponds to the .qmd file on your GitHub repository in order to receive credit for this portion of the exam.\nYou must upload a PDF, not HTML. Any non-PDF submissions will not be graded.\nMark the pages associated with each question. If any answer for a question spans multiple pages, mark all associated pages.\nMake sure to associate the ‚ÄúWorkflow & formatting‚Äù section with the first page.\nFailure to mark the pages in Gradescope will result in point deductions. Any pages that are not marked will not be graded.\nMake sure that your uploaded PDF document matches your .qmd and the PDF in your GitHub repository exactly. Points will be deducted for documents that are not reproducible."
  },
  {
    "objectID": "exams/exam-3.html",
    "href": "exams/exam-3.html",
    "title": "Exam 2",
    "section": "",
    "text": "Exam 3 is released on Friday, April 15 at 9 am ET and must be completed by Mon, April 18 at 11:59 pm.\nThe exam will consist of two parts:\n\nPart 1 - Conceptual: Multiple choice questions on Sakai test and quizzes.\n\nGo here to complete Part 1 of the exam.\nThis portion is comprised of 10 multiple choice / fill in the blank questions may only be submitted one time, so start it when you can set aside ~30 minutes to work on it. You will likely be done quicker but it‚Äôs best to set aside ample time.\n\nPart 2 - Applied: Data analysis in RStudio and submitted in Gradescope, like a usual lab and homework.\n\nGo to the GitHub organization for the course and find the exam-3- repo to complete Part 2 of your exam.\nAdd your answers to the exam-3.qmd file in your repo.\nYou can work on this portion at your own pace and come back to it however many times you like until the deadline. I recommend setting aside ~2 hours. You will likely be done quicker, but it‚Äôs best to set aside ample time.\n\n\nBoth portions must be completed and submitted by Mon, April 18 at 11:59 pm. Late work will only be accepted in the case of of extenuating circumstances and notification from your academic dean.\nüçÄ Good luck! üçÄ\n\n\n\nBy taking this exam, you pledge to uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised.\n\n\n\n\n\nThis is an individual assignment. Everything in your repository and on Sakai is for your eyes only.\nYou may not collaborate or communicate anything about this exam to anyone except the instructor and the head TA (Rick Presman). For example, you may not communicate with other students, other TAs, or post/solicit help on the internet, email or via any other method of communication.\nThe exam is open-book, open-note, so you may use any materials from class as you take the exam.\nOnly head TA and professor office hours will be held during the exam period.\nYou may not email the TAs questions about the exam.\nIf you have questions, direct message the professor on Slack or email or request an appointment to meet on Zoom.\n\n\n\n\n\nPart 1 - Conceptual: The answers to the multiple choice/short answer questions should be submitted under Test & Quizzes in Sakai.\nPart 2 - Applied: The PDF document for the data analysis portion must be uploaded to Gradescope.\n\nYou must submit a PDF to Gradescope that corresponds to the .qmd file on your GitHub repository in order to receive credit for this portion of the exam.\nYou must upload a PDF, not HTML. Any non-PDF submissions will not be graded.\nMark the pages associated with each question. If any answer for a question spans multiple pages, mark all associated pages.\nMake sure to associate the ‚ÄúWorkflow & formatting‚Äù section with the first page.\nFailure to mark the pages in Gradescope will result in point deductions. Any pages that are not marked will not be graded.\nMake sure that your uploaded PDF document matches your .qmd and the PDF in your GitHub repository exactly. Points will be deducted for documents that are not reproducible."
  },
  {
    "objectID": "exams/exam-3.html#overview",
    "href": "exams/exam-3.html#overview",
    "title": "Exam 2",
    "section": "",
    "text": "Exam 3 is released on Friday, April 15 at 9 am ET and must be completed by Mon, April 18 at 11:59 pm.\nThe exam will consist of two parts:\n\nPart 1 - Conceptual: Multiple choice questions on Sakai test and quizzes.\n\nGo here to complete Part 1 of the exam.\nThis portion is comprised of 10 multiple choice / fill in the blank questions may only be submitted one time, so start it when you can set aside ~30 minutes to work on it. You will likely be done quicker but it‚Äôs best to set aside ample time.\n\nPart 2 - Applied: Data analysis in RStudio and submitted in Gradescope, like a usual lab and homework.\n\nGo to the GitHub organization for the course and find the exam-3- repo to complete Part 2 of your exam.\nAdd your answers to the exam-3.qmd file in your repo.\nYou can work on this portion at your own pace and come back to it however many times you like until the deadline. I recommend setting aside ~2 hours. You will likely be done quicker, but it‚Äôs best to set aside ample time.\n\n\nBoth portions must be completed and submitted by Mon, April 18 at 11:59 pm. Late work will only be accepted in the case of of extenuating circumstances and notification from your academic dean.\nüçÄ Good luck! üçÄ"
  },
  {
    "objectID": "exams/exam-3.html#academic-integrity",
    "href": "exams/exam-3.html#academic-integrity",
    "title": "Exam 2",
    "section": "",
    "text": "By taking this exam, you pledge to uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised."
  },
  {
    "objectID": "exams/exam-3.html#rules-notes",
    "href": "exams/exam-3.html#rules-notes",
    "title": "Exam 2",
    "section": "",
    "text": "This is an individual assignment. Everything in your repository and on Sakai is for your eyes only.\nYou may not collaborate or communicate anything about this exam to anyone except the instructor and the head TA (Rick Presman). For example, you may not communicate with other students, other TAs, or post/solicit help on the internet, email or via any other method of communication.\nThe exam is open-book, open-note, so you may use any materials from class as you take the exam.\nOnly head TA and professor office hours will be held during the exam period.\nYou may not email the TAs questions about the exam.\nIf you have questions, direct message the professor on Slack or email or request an appointment to meet on Zoom."
  },
  {
    "objectID": "exams/exam-3.html#submission",
    "href": "exams/exam-3.html#submission",
    "title": "Exam 2",
    "section": "",
    "text": "Part 1 - Conceptual: The answers to the multiple choice/short answer questions should be submitted under Test & Quizzes in Sakai.\nPart 2 - Applied: The PDF document for the data analysis portion must be uploaded to Gradescope.\n\nYou must submit a PDF to Gradescope that corresponds to the .qmd file on your GitHub repository in order to receive credit for this portion of the exam.\nYou must upload a PDF, not HTML. Any non-PDF submissions will not be graded.\nMark the pages associated with each question. If any answer for a question spans multiple pages, mark all associated pages.\nMake sure to associate the ‚ÄúWorkflow & formatting‚Äù section with the first page.\nFailure to mark the pages in Gradescope will result in point deductions. Any pages that are not marked will not be graded.\nMake sure that your uploaded PDF document matches your .qmd and the PDF in your GitHub repository exactly. Points will be deducted for documents that are not reproducible."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 210: Regression Analysis",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester. Note that this schedule will be updated as the semester progresses, with all changes documented here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek\nDate\nTopic\nPrepare\nSlides\nAE\nLab\nHW\nExam\nProject\n\n\n\n\n1\nWed, Jan 5\nLab 0 - Meet + greet\n\nüñ•Ô∏è\n\nüíª\n\n\n\n\n\n\nThu, Jan 6\nWelcome to STA 210!\nüìñ\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n2\nMon, Jan 10\nLab 1 - Meet the toolkit\n\nüñ•Ô∏è\n\nüíª\n\n\n\n\n\n\nTue, Jan 11\nSimple linear regression (SLR)\nüìñ\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nThu, Jan 13\nSLR: Model fitting in R with tidymodels\n\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\nFri, Jan 14\nReleased: HW 5\n\n\n\n\n‚úçÔ∏è\n\n\n\n\n\n\nDue: Lab 1\n\n\n\nüíª üóùÔ∏è\n\n\n\n\n\n3\nMon, Jan 17\nMartin Luther King, Jr.¬†Day\n\n\n\n\n\n\n\n\n\n\nTue, Jan 18\nSLR: Prediction + model evaluation\nüìñ\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\nThu, Jan 20\nSLR: Simulation-based inference\n\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nFri, Jan 21\nReleased: HW 1\n\n\n\n\n‚úçÔ∏è\n\n\n\n\n4\nMon, Jan 24\nLab 2 - College scorecard\n\nüñ•Ô∏è\n\nüíª\n\n\n\n\n\n\nTue, Jan 25\nSLR: Mathematical models for inference\nüìñ\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nThu, Jan 27\nSLR: Model diagnostics\n\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\nFri, Jan 28\nDue: HW 1 + Lab 2\n\n\n\nüíª üóùÔ∏è\n‚úçÔ∏è üóùÔ∏è\n\n\n\n\n5\nMon, Jan 31\nLab 3 - Coffee ratings\n\nüñ•Ô∏è\n\nüíª\n\n\n\n\n\n\nTue, Feb 1\nMultiple linear regression (MLR)\nüìñ\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nThu, Feb 3\nExam 1 review\n\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\nFri, Feb 4\nReleased: Exam 1\n\n\n\n\n\n‚úÖ\n\n\n\n\n\nDue: Lab 3\n\n\n\nüíª üóùÔ∏è\n\n\n\n\n\n6\nMon, Feb 7\nNo lab: Work on Exam 1\n\n\n\n\n\n\n\n\n\n\n\nDue: Exam 1\n\n\n\n\n\n‚úÖ\n\n\n\n\nTue, Feb 8\nMLR: Types of predictors\nüìñ\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nThu, Feb 10\nMLR: Model comparison\n\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nFri, Feb 11\nReleased: HW 2\n\n\n\n\n‚úçÔ∏è\n\n\n\n\n7\nMon, Feb 14\nLab: Project topic ideas\n\n\n\n\n\n\nüìÇ\n\n\n\nTue, Feb 15\nMLR: Feature engineering\nüìñ\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\nThu, Feb 17\nMLR: Feature engineering\n\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nFri, Feb 18\nDue: HW 2 + Project topic ideas\n\n\n\n\n‚úçÔ∏è üóùÔ∏è\n\nüìÇ\n\n\n8\nMon, Feb 21\nLab 4: The Office\n\n\n\nüíª\n\n\n\n\n\n\nTue, Feb 22\nMLR: Cross validation\nüìñ\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\nThu, Feb 24\nExam 2 review\n\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\nFri, Feb 25\nReleased: Exam 2\n\n\n\n\n\n‚úÖ\n\n\n\n\n\nDue: Lab 4\n\n\n\nüíª üóùÔ∏è\n\n\n\n\n\n9\nMon, Feb 28\nNo lab: Work on Exam 2\n\n\n\n\n\n\n\n\n\n\n\nDue: Exam 2\n\n\n\n\n\n‚úÖ\n\n\n\n\nTue, Mar 1\nMLR: Inference\nüìñ\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\nThu, Mar 3\nMLR: Inference conditions + multicollinearity\n\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nMon, Mar 7\nSpring break\n\n\n\n\n\n\n\n\n\n\nTue, Mar 8\nSpring break\n\n\n\n\n\n\n\n\n\n\nThu, Mar 10\nSpring break\n\n\n\n\n\n\n\n\n\n10\nMon, Mar 14\nLab: Work on project proposals\n\n\n\n\n\n\nüìÇ\n\n\n\nTue, Mar 15\nLogistic regression (LR)\nüìñ\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\nThu, Mar 17\nProbabilities, odds, and odds ratios\n\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nFri, Mar 18\nDue: Project proposals\n\n\n\n\n\n\nüìÇ\n\n\n\n\nReleased: HW 3\n\n\n\n\n‚úçÔ∏è\n\n\n\n\n11\nMon, Mar 21\nLab 5: General Social Survey\n\n\n\nüíª\n\n\n\n\n\n\nTue, Mar 22\nLR: Prediction / classification\nüìñ\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nThu, Mar 24\nLR: Model comparison\n\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\nFri, Mar 25\nDue: HW 3 + Lab 5\n\n\n\nüíª üóùÔ∏è\n‚úçÔ∏è üóùÔ∏è\n\n\n\n\n12\nMon, Mar 28\nLab: Work on project drafts\n\n\n\n\n\n\nüìÇ\n\n\n\nTue, Mar 29\nLR: Inference + conditions\nüìñ\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nThu, Mar 31\nMultinomial Logistic Regression (MultiLR)\n\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nFri, Apr 1\nReleased: HW 4\n\n\n\n\n‚úçÔ∏è\n\n\n\n\n13\nMon, Apr 4\nLab 6: Why Many Americans Don‚Äôt Vote\n\n\n\nüíª\n\n\n\n\n\n\nTue, Apr 5\nMultiLR: Prediction + inferential models\nüìñ\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nThu, Apr 7\nMultiLR: Predictive models\n\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\nFri, Apr 8\nDue: Lab 6\n\n\n\nüíª üóùÔ∏è\n\n\n\n\n\n\nSun, Apr 10\nDue: Project drafts\n\n\n\n\n\n\nüìÇ\n\n\n14\nMon, Apr 11\nLab: Project peer review of drafts\n\n\n\n\n\n\nüìÇ\n\n\n\nTue, Apr 12\nMultiLR: Predictive models (cont.)\nüìñ\nüñ•Ô∏è\n\n\n\n\n\n\n\n\n\nDue: HW 4\n\n\n\n\n‚úçÔ∏è üóùÔ∏è\n\n\n\n\n\nThu, Apr 14\nExam 3 review\n\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\n\nDue: Peer review\n\n\n\n\n\n\nüìÇ\n\n\n\nFri, Apr 15\nReleased: Exam 3\n\n\n\n\n\n‚úÖ\n\n\n\n15\nMon, Apr 18\nNo lab: Work on Exam 3\n\n\n\n\n\n\n\n\n\n\n\nDue: Exam 3\n\n\n\n\n\n‚úÖ\n\n\n\n\nTue, Apr 19\nWrap-up\nüìñ\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\n\nDue: HW 5\n\n\n\n\n‚úçÔ∏è\n\n\n\n\n16\nMon, Apr 25\nDue: Project write-up\n\n\n\n\n\n\nüìÇ\n\n\n\nThu, Apr 28\nDue: Video presentation + repo\n\n\n\n\n\n\nüìÇ\n\n\n\nSat, Apr 30\nDue: Video comments\n\n\n\n\n\n\nüìÇ",
    "crumbs": [
      "Course information",
      "Schedule"
    ]
  },
  {
    "objectID": "project-description.html",
    "href": "project-description.html",
    "title": "Project description",
    "section": "",
    "text": "Topic ideas due Fri, Feb 18\nProposal due Fri, Mar 18\nDraft report due Fri, Apr 8\nPeer review due Fri, Apr 15\nFinal report due Mon, Apr 25\nVideo presentation + slides and final GitHub repo due Thu, Apr 28\nPresentation comments due Sat, Apr 30",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project-description.html#timeline",
    "href": "project-description.html#timeline",
    "title": "Project description",
    "section": "",
    "text": "Topic ideas due Fri, Feb 18\nProposal due Fri, Mar 18\nDraft report due Fri, Apr 8\nPeer review due Fri, Apr 15\nFinal report due Mon, Apr 25\nVideo presentation + slides and final GitHub repo due Thu, Apr 28\nPresentation comments due Sat, Apr 30",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project-description.html#introduction",
    "href": "project-description.html#introduction",
    "title": "Project description",
    "section": "Introduction",
    "text": "Introduction\nTL;DR: Pick a data set and do a regression analysis. That is your final project.\nThe goal of the final project is for you to use regression analysis to analyze a data set of your own choosing. The data set may already exist or you may collect your own data by scraping the web.\nChoose the data based on your group‚Äôs interests or work you all have done in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio, and all components of the project must be reproducible (with the exception of the presentation).\n\nLogistics\nYou will work on the project with your lab groups.\nThe four primary deliverables for the final project are\n\nA written, reproducible report detailing your analysis\nA GitHub repository corresponding to your report\nSlides + a video presentation\nFormal peer review on another team‚Äôs project",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project-description.html#topic-ideas",
    "href": "project-description.html#topic-ideas",
    "title": "Project description",
    "section": "Topic ideas",
    "text": "Topic ideas\nIdentify 2-3 data sets you‚Äôre interested in potentially using for the final project. If you‚Äôre unsure where to find data, you can use the list of potential data sources in the Tips + Resources section as a starting point. It may also help to think of topics you‚Äôre interested in investigating and find data sets on those topics.\nThe purpose of submitting project ideas is to give you time to find data for the project and to make sure you have a data set that can help you be successful in the project. Therefore, you must use one of the data sets submitted as a topic idea, unless otherwise notified by the teaching team.\nThe data sets should meet the following criteria:\n\nAt least 500 observations\nAt least 10 columns\nAt least 6 of the columns must be useful and unique predictor variables.\n\nIdentifier variables such as ‚Äúname‚Äù, ‚Äúsocial security number‚Äù, etc. are not useful predictor variables.\nIf you have multiple columns with the same information (e.g.¬†‚Äústate abbreviation‚Äù and ‚Äústate name‚Äù), then they are not unique predictors.\n\nAt least one variable that can be identified as a reasonable response variable.\n\nThe response variable can be quantitative or categorical.\n\nA mix of quantitative and categorical variables that can be used as predictors.\nObservations should reasonably meet the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\nYou may not use data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\nPlease ask a member of the teaching team if you‚Äôre unsure whether your data set meets the criteria.\nFor each data set, include the following:\n\nIntroduction and data\n\nState the source of the data set.\nDescribe when and how it was originally collected (by the original data curator, not necessarily how you found the data)\nDescribe the observations and the general characteristics being measured in the data\n\n\n\nResearch question\n\nDescribe a research question you‚Äôre interested in answering using this data.\n\n\n\nGlimpse of data\n\nUse the glimpse function to provide an overview of each data set\n\nSubmit the PDF of the topic ideas to Gradescope. Mark all pages associated with each data set.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project-description.html#project-proposal",
    "href": "project-description.html#project-proposal",
    "title": "Project description",
    "section": "Project proposal",
    "text": "Project proposal\nThe purpose of the project proposal is to help you think about your analysis strategy early.\nInclude the following in the proposal:\n\nSection 1 - Introduction\nThe introduction section includes\n\nan introduction to the subject matter you‚Äôre investigating\nthe motivation for your research question (citing any relevant literature)\nthe general research question you wish to explore\nyour hypotheses regarding the research question of interest.\n\n\n\nSection 2 - Data description\nIn this section, you will describe the data set you wish to explore. This includes\n\ndescription of the observations in the data set,\ndescription of how the data was originally collected (not how you found the data but how the original curator of the data collected it).\n\n\n\nSection 3 - Analysis approach\nIn this section, you will provide a brief overview of your analysis approach. This includes:\n\nDescription of the response variable.\nVisualization and summary statistics for the response variable.\nList of variables that will be considered as predictors\nRegression model technique (multiple linear regression and logistic regression)\n\n\n\nData dictionary (aka code book)\nSubmit a data dictionary for all the variables in your data set in the README of your project repo, in the data folder. Link to this file from your proposal writeup.\n\n\nSubmission\nPush all of your final changes to the GitHub repo, and submit the PDF of your proposal to Gradescope.\n\n\nProposal grading\n\n\n\nTotal\n10 pts\n\n\n\n\nIntroduction\n3 pts\n\n\nData description\n2 pts\n\n\nAnalysis plan\n4 pts\n\n\nData dictionary\n1 pts\n\n\n\nEach component will be graded as follows:\n\nMeets expectations (full credit): All required elements are completed and are accurate. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nClose to expectations (half credit): There are some elements missing and/or inaccurate. There are some issues with formatting.\nDoes not meet expectations (no credit): Major elements missing. Work is not neatly formatted and would not be presentable in a professional setting.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project-description.html#draft-report",
    "href": "project-description.html#draft-report",
    "title": "Project description",
    "section": "Draft report",
    "text": "Draft report\nThe purpose of the draft and peer review is to give you an opportunity to get early feedback on your analysis. Therefore, the draft and peer review will focus primarily on the exploratory data analysis, modeling, and initial interpretations.\nWrite the draft in the written-report.qmd file in your project repo. You do not need to submit the draft on Gradescope.\nBelow is a brief description of the sections to focus on in the draft:\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won‚Äôt fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you‚Äôre fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, any variable transformations (if needed), and any other relevant considerations that were part of the model fitting process.\n\n\nResults\nIn this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics.\nThis section also includes initial interpretations and conclusions drawn from the model.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project-description.html#peer-review",
    "href": "project-description.html#peer-review",
    "title": "Project description",
    "section": "Peer review",
    "text": "Peer review\nCritically reviewing others‚Äô work is a crucial part of the scientific process, and STA 210 is no exception. Each lab team will be assigned two other teams‚Äôs projects to review. Each team should push their draft to their GitHub repo by the due date. One lab in the following week will be dedicated to the peer review, and all reviews will be due by the end of that lab session.\nDuring the peer review process, you will be provided read-only access to your partner teams‚Äô GitHub repos. Provide your review in the form of GitHub issues to your partner team‚Äôs GitHub repo using the issue template provided. The peer review will be graded on the extent to which it comprehensively and constructively addresses the components of the partner team‚Äôs report: the research context and motivation, exploratory data analysis, modeling, interpretations, and conclusions.\n\nPairings\n\nSection 1 - M 1:45PM - 3:00PM\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\nchaa_chaa_chaa\nyay_stats\nstat_over_flow\n\n\ndekk\nchaa_chaa_chaa\nyay_stats\n\n\neight\ndekk\nchaa_chaa_chaa\n\n\nhousecats\neight\ndekk\n\n\nkrafthouse\nhousecats\neight\n\n\nrrawr\nkrafthouse\nhousecats\n\n\nstat_over_flow\nrrawr\nkrafthouse\n\n\nyay_stats\nstat_over_flow\nrrawr\n\n\n\n\n\nSection 2 - M 3:30PM - 4:45PM\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\na_plus_plus_plus\nwe_r\ntina\n\n\npredictors\na_plus_plus_plus\nwe_r\n\n\nsixers\npredictors\na_plus_plus_plus\n\n\nsoy_nuggets\nsixers\npredictors\n\n\ntina\nsoy_nuggets\nsixers\n\n\nwe_r\ntina\nsoy_nuggets\n\n\n\n\n\nSection 3 - M 5:15PM - 6:30PM\n\n\n\n\n\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\ndown_to_earth_goats\nthe_three_musketeers\nteam_five\n\n\nginger_and_stats\ndown_to_earth_goats\nthe_three_musketeers\n\n\npineapple_wedge_and_diced_papaya\nginger_and_stats\ndown_to_earth_goats\n\n\nstatchelorettes\npineapple_wedge_and_diced_papaya\nginger_and_stats\n\n\nstatisix\nstatchelorettes\npineapple_wedge_and_diced_papaya\n\n\nstats_squad\nstatisix\nstatchelorettes\n\n\nteam_five\nstats_squad\nstatisix\n\n\nthe_three_musketeers\nteam_five\nstats_squad\n\n\n\n\n\n\nProcess and questions\nSpend ~30 mins to review each team‚Äôs project.\n\nFind your team name on the Reviewer 1 and Reviewer 2 columns.\nFor each of the columns, find the name of the team to review in the Team being reviewed column. You should already have access to this team‚Äôs repo.\nOpen the repo of the team you‚Äôre reviewing, read their project draft, and browser around the rest of their repo.\nThen, go to the Issues tab in that repo, click on New issue, and click on Get started for the Peer review issue. Fill out this issue, answering the following questions:\n\nPeer review by: [NAME OF TEAM DOING THE REVIEW]\nNames of team members that participated in this review: [FULL NAMES OF TEAM MEMBERS DOING THE REVIEW]\nDescribe the goal of the project.\nDescribe the data used or collected, if any. If the proposal does not include the use of a specific dataset, comment on whether the project would be strengthened by the inclusion of a dataset.\nDescribe the approaches, tools, and methods that will be used.\nIs there anything that is unclear from the proposal?\nProvide constructive feedback on how the team might be able to improve their project. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but do feel free to comment on aspects beyond the modeling.\nWhat aspect of this project are you most interested in and would like to see highlighted in the presentation.\nProvide constructive feedback on any issues with file and/or code organization.\n(Optional) Any further comments or feedback?",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project-description.html#written-report",
    "href": "project-description.html#written-report",
    "title": "Project description",
    "section": "Written report",
    "text": "Written report\nYour written report must be completed in the written-report.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the printing of code chunks is off with the option echo = FALSE.\nYou will submit the PDF of your final report on Gradescope.\nThe PDF you submit must match the files in your GitHub repository exactly. The mandatory components of the report are below. You are free to add additional sections as necessary. The report, including visualizations, should be no more than 10 pages long. is no minimum page requirement; however, you should comprehensively address all of the analysis and report.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will largely be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\nThe written report is worth 40 points, broken down as follows\n\n\n\nTotal\n40 pts\n\n\n\n\nIntroduction/data\n6 pts\n\n\nMethodology\n10 pts\n\n\nResults\n14 pts\n\n\nDiscussion + conclusion\n6 pts\n\n\nOrganization + formatting\n4 pts\n\n\n\nClick here for a PDF of the written report rubric.\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won‚Äôt fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\nGrading criteria\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The explanatory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you‚Äôre fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\nGrading criteria\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to select the final model; the approach is clearly described in the report. The model selection process took into account potential interaction effects and addressed any violations in model conditions. The model conditions and diagnostics are thoroughly and accurately assessed for their model. If violations of model conditions are still present, there was a reasonable attempt to address the violations based on the course content.\n\n\n\nResults\nThis is where you will output the final model with any relevant model fit statistics.\nDescribe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\nGrading criteria\nThe model fit is clearly assessed, and interesting findings from the model are clearly described. Interpretations of model coefficients are used to support the key findings and conclusions, rather than merely listing the interpretation of every model coefficient. If the primary modeling objective is prediction, the model‚Äôs predictive power is thoroughly assessed.\n\n\n\nDiscussion + Conclusion\nIn this section you‚Äôll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\nGrading criteria\nOverall conclusions from analysis are clearly described, and the model results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report.\n\nGrading criteria\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project-description.html#video-presentation-slides",
    "href": "project-description.html#video-presentation-slides",
    "title": "Project description",
    "section": "Video presentation + slides",
    "text": "Video presentation + slides\n\nSlides\nIn addition to the written report, your team will also create presentation slides and record a video presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. These slides should serve as a brief visual addition to your written report and will be graded for content and quality.\nFor submission, convert these slides to a .pdf document, and submit the PDF of the slides on Gradescope.\nThe slide deck should have no more than 6 content slides + 1 title slide. Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3: Highlights from EDA\nSlide 4: Final model\nSlide 5: Interesting findings from the model\nSlide 6: Conclusions + future work\n\n\n\nVideo presentation\nFor the video presentation, you can speak over your slide deck, similar to the lecture content videos. The video presentation must be no longer than 8 minutes. It is fine if the video is shorter than 8 minutes, but it cannot exceed 8 minutes. You may use can use any platform that works best for your group to record your presentation. Below are a few resources on recording videos:\n\nRecording presentations in Zoom\nApple Quicktime for screen recording\nWindows 10 built-in screen recording functionality\nKap for screen recording\n\nOnce your video is ready, upload the video to Warpwire, then embed the video in an new discussion post on Conversations.\n\nTo upload your video to Warpwire:\n\nClick the Warpwire tab in the course Sakai site.\nClick the ‚Äú+‚Äù and select ‚ÄúUpload files‚Äù.\nLocate the video on your computer and click to upload.\nOnce you‚Äôve uploaded the video to Warpwire, click to share the video and copy the video‚Äôs URL. You will need this when you post the video in the discussion forum.\n\n\n\nTo post the video to the discussion forum\n\nClick the Presentations tab in the course Sakai site.\nClick the Presentations topic.\nClick ‚ÄúStart a new conversation‚Äù.\nMake the title ‚ÄúYour Team Name: Project Title‚Äù. For example, ‚ÄúTeaching Team: Our Awesome Presentation‚Äù.\nClick the Warpwire icon (between the table and shopping cart icons).\nSelect your video, then click ‚ÄúInsert 1 item.‚Äù This will embed your video in the conversation.\nUnder the video, paste the URL to your video.\nYou‚Äôre done!",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project-description.html#presentation-comments",
    "href": "project-description.html#presentation-comments",
    "title": "Project description",
    "section": "Presentation comments",
    "text": "Presentation comments\nEach student will be assigned 2 presentations to watch. Your viewing assignments will be posted later in the semester.\nWatch the group‚Äôs video, then click ‚ÄúReply‚Äù to post a question for the group. You may not post a question that‚Äôs already been asked on the discussion thread. Additionally, the question should be (i) substantive (i.e.¬†it shouldn‚Äôt be ‚ÄúWhy did you use a bar plot instead of a pie chart‚Äù?), (ii) demonstrate your understanding of the content from the course, and (iii) relevant to that group‚Äôs specific presentation, i.e demonstrating that you‚Äôve watched the presentation.\nThis portion of the project will be assessed individually.\n\nPairings\nFind your team name in the first column, watch videos from teams in the second column and leave comments.\n\n\n\n\n\n\n\n\nReviewer\nFirst video to review\nSecond video to review\n\n\n\n\nGinger and Stats\nEight\nWe R\n\n\nKrafthouse\nGinger and Stats\nEight\n\n\nSoy Nuggets\nKrafthouse\nGinger and Stats\n\n\nDown To Earth Goats\nSoy Nuggets\nKrafthouse\n\n\nA+++\nDown To Earth Goats\nSoy Nuggets\n\n\nTeam Five\nA+++\nDown To Earth Goats\n\n\nRrawr\nTeam Five\nA+++\n\n\nHousecats\nRrawr\nTeam Five\n\n\nDekk\nHousecats\nRrawr\n\n\nStat OverFlow\nDekk\nHousecats\n\n\nThe Three Musketeers\nStat OverFlow\nDekk\n\n\nPredictors\nThe Three Musketeers\nStat OverFlow\n\n\nStats Squad\nPredictors\nThe Three Musketeers\n\n\nStatisix\nStats Squad\nPredictors\n\n\nSixers\nStatisix\nStats Squad\n\n\nYay Stats\nSixers\nStatisix\n\n\nTINA\nYay Stats\nSixers\n\n\nStatchelorettes\nTINA\nYay Stats\n\n\nPineapple Wedge and Diced Papaya\nStatchelorettes\nTINA\n\n\nChaa Chaa Chaa\nPineapple Wedge and Diced Papaya\nStatchelorettes\n\n\nWe R\nChaa Chaa Chaa\nPineapple Wedge and Diced Papaya\n\n\nEight\nWe R\nChaa Chaa Chaa",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project-description.html#reproducibility-organization",
    "href": "project-description.html#reproducibility-organization",
    "title": "Project description",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nThe GitHub repo should have the following structure:\n\nREADME: Short project description and data dictionary\nwritten-report.qmd & written-report.pdf: Final written report\n/data: Folder that contains the data set for the final project.\n/previous-work: Folder that contains the topic-ideas and project-proposal files.\n/presentation: Folder with the presentation slides.\n\nIf your presentation slides are online, you can put a link to the slides in a README.md file in the presentation folder.\n\n\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project-description.html#peer-teamwork-evaluation",
    "href": "project-description.html#peer-teamwork-evaluation",
    "title": "Project description",
    "section": "Peer teamwork evaluation",
    "text": "Peer teamwork evaluation\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly.\nIf you have concerns with the teamwork and/or contribution from any team members, please email me by the project video deadline. You only need to email me if you have concerns. Otherwise, I will assume everyone on the team equally contributed and will receive full credit for the teamwork portion of the grade.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project-description.html#overall-grading",
    "href": "project-description.html#overall-grading",
    "title": "Project description",
    "section": "Overall grading",
    "text": "Overall grading\nThe grade breakdown is as follows:\n\n\n\nTotal\n100 pts\n\n\n\n\nTopic ideas\n5 pts\n\n\nProject proposal\n10 pts\n\n\nPeer review\n10 pts\n\n\nWritten report\n40 pts\n\n\nSlides + video presentation\n20 pts\n\n\nReproducibility + organization\n5 pts\n\n\nVideo comments\n5 pts\n\n\nPeer teamwork evaluation\n5 pts\n\n\n\nNote: No late project reports or videos are accepted.\n\nGrading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort.\n\n\n\nLate work policy\nThere is no late work accepted on this project. Be sure to turn in your work early to avoid any technological mishaps.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "supplemental/log-transformations.html",
    "href": "supplemental/log-transformations.html",
    "title": "Log Transformations in Linear Regression",
    "section": "",
    "text": "Note\n\n\n\nThe following supplemental notes were created by Dr.¬†Maria Tackett for STA 210. They are provided for students who want to dive deeper into the mathematics behind regression and reflect some of the material covered in STA 211: Mathematics of Regression. Additional supplemental notes will be added throughout the semester.\nThis document provides details about the model interpretation when the predictor and/or response variables are log-transformed. For simplicity, we will discuss transformations for the simple linear regression model as shown in Equation¬†1.\n\\[\n\\label{orig}\ny = \\beta_0 + \\beta_1 x\n\\tag{1}\\]\nAll results and interpretations can be easily extended to transformations in multiple regression models.\nNote: log refers to the natural logarithm.",
    "crumbs": [
      "Supplemental notes",
      "Log transformations"
    ]
  },
  {
    "objectID": "supplemental/log-transformations.html#log-transformation-on-the-response-variable",
    "href": "supplemental/log-transformations.html#log-transformation-on-the-response-variable",
    "title": "Log Transformations in Linear Regression",
    "section": "Log-transformation on the response variable",
    "text": "Log-transformation on the response variable\nSuppose we fit a linear regression model with \\(\\log(y)\\), the log-transformed \\(y\\), as the response variable. Under this model, we assume a linear relationship exists between \\(x\\) and \\(\\log(y)\\), such that \\(\\log(y) \\sim N(\\beta_0 + \\beta_1 x, \\sigma^2)\\) for some \\(\\beta_0\\), \\(\\beta_1\\) and \\(\\sigma^2\\). In other words, we can model the relationship between \\(x\\) and \\(\\log(y)\\) using the model in Equation¬†2.\n\\[\n\\log(y) = \\beta_0 + \\beta_1 x\n\\tag{2}\\]\nIf we interpret the model in terms of \\(\\log(y)\\), then we can use the usual interpretations for slope and intercept. When reporting results, however, it is best to give all interpretations in terms of the original response variable \\(y\\), since interpretations using log-transformed variables are often more difficult to truly understand.\nIn order to get back on the original scale, we need to use the exponential function (also known as the anti-log), \\(\\exp\\{x\\} = e^x\\). Therefore, we use the model in Equation¬†2 for interpretations and predictions, we will use Equation¬†3 to state our conclusions in terms of \\(y\\).\n\\[\n\\begin{aligned}\n&\\exp\\{\\log(y)\\} = \\exp\\{\\beta_0 + \\beta_1 x\\} \\\\[10pt]\n\\Rightarrow &y = \\exp\\{\\beta_0 + \\beta_1 x\\} \\\\[10pt]\n\\Rightarrow &y = \\exp\\{\\beta_0\\}\\exp\\{\\beta_1 x\\}\n\\end{aligned}\n\\tag{3}\\]\nIn order to interpret the slope and intercept, we need to first understand the relationship between the mean, median and log transformations.\n\nMean, Median, and Log Transformations\nSuppose we have a dataset y that contains the following observations:\n\n\n[1] 3 5 6 7 8\n\n\nIf we log-transform the values of y then calculate the mean and median, we have\n\n\n\n\n\nmean_log_y\nmedian_log_y\n\n\n\n\n1.70503\n1.79176\n\n\n\n\n\nIf we calculate the mean and median of y, then log-transform the mean and median, we have\n\n\n\n\n\nlog_mean\nlog_median\n\n\n\n\n1.75786\n1.79176\n\n\n\n\n\nThis is a simple illustration to show\n\n\\(\\text{Mean}[{\\log(y)}] \\neq \\log[\\text{Mean}(y)]\\) - the mean and log are not commutable\n\\(\\text{Median}[\\log(y)] = \\log[\\text{Median}(y)]\\) - the median and log are commutable\n\n\n\nInterpretaton of model coefficients\nUsing Equation¬†2, the mean \\(\\log(y)\\) for any given value of \\(x\\) is \\(\\beta_0 + \\beta_1 x\\); however, this does not indicate that the mean of \\(y = \\exp\\{\\beta_0 + \\beta_1 x\\}\\) (see previous section). From the assumptions of linear regression, we assume that for any given value of \\(x\\), the distribution of \\(\\log(y)\\) is Normal, and therefore symmetric. Thus the median of \\(\\log(y)\\) is equal to the mean of \\(\\log(y)\\), i.e \\(\\text{Median}(\\log(y)) = \\beta_0 + \\beta_1 x\\).\nSince the log and the median are commutable, \\(\\text{Median}(\\log(y)) = \\beta_0 + \\beta_1 x \\Rightarrow \\text{Median}(y) = \\exp\\{\\beta_0 + \\beta_1 x\\}\\). Thus, when we log-transform the response variable, the interpretation of the intercept and slope are in terms of the effect on the median of \\(y\\).\nIntercept: The intercept is expected median of \\(y\\) when the predictor variable equals 0. Therefore, when \\(x=0\\),\n\\[\n\\begin{aligned}\n&\\log(y) = \\beta_0 + \\beta_1 \\times 0 = \\beta_0 \\\\[10pt]\n\\Rightarrow &y = \\exp\\{\\beta_0\\}\n\\end{aligned}\n\\]\nInterpretation: When \\(x=0\\), the median of \\(y\\) is expected to be \\(\\exp\\{\\beta_0\\}\\).\nSlope: The slope is the expected change in the median of \\(y\\) when \\(x\\) increases by 1 unit. The change in the median of \\(y\\) is\n\\[\n\\exp\\{[\\beta_0 + \\beta_1 (x+1)] - [\\beta_0 + \\beta_1 x]\\} = \\frac{\\exp\\{\\beta_0 + \\beta_1 (x+1)\\}}{\\exp\\{\\beta_0 + \\beta_1 x\\}} = \\frac{\\exp\\{\\beta_0\\}\\exp\\{\\beta_1 x\\}\\exp\\{\\beta_1\\}}{\\exp\\{\\beta_0\\}\\exp\\{\\beta_1 x\\}} = \\exp\\{\\beta_1\\}\n\\]\nThus, the median of \\(y\\) for \\(x+1\\) is \\(\\exp\\{\\beta_1\\}\\) times the median of \\(y\\) for \\(x\\).\nInterpretation: When \\(x\\) increases by one unit, the median of \\(y\\) is expected to multiply by a factor of \\(\\exp\\{\\beta_1\\}\\).",
    "crumbs": [
      "Supplemental notes",
      "Log transformations"
    ]
  },
  {
    "objectID": "supplemental/log-transformations.html#log-transformation-on-the-predictor-variable",
    "href": "supplemental/log-transformations.html#log-transformation-on-the-predictor-variable",
    "title": "Log Transformations in Linear Regression",
    "section": "Log-transformation on the predictor variable",
    "text": "Log-transformation on the predictor variable\nSuppose we fit a linear regression model with \\(\\log(x)\\), the log-transformed \\(x\\), as the predictor variable. Under this model, we assume a linear relationship exists between \\(\\log(x)\\) and \\(y\\), such that \\(y \\sim N(\\beta_0 + \\beta_1 \\log(x), \\sigma^2)\\) for some \\(\\beta_0\\), \\(\\beta_1\\) and \\(\\sigma^2\\). In other words, we can model the relationship between \\(\\log(x)\\) and \\(y\\) using the model in #eq-log-x.\n\\[\ny = \\beta_0 + \\beta_1 \\log(x)\n\\tag{4}\\]\nIntercept: The intercept is the mean of \\(y\\) when \\(\\log(x) = 0\\), i.e.¬†\\(x = 1\\).\nInterpretation: When \\(x = 1\\) \\((\\log(x) = 0)\\), the mean of \\(y\\) is expected to be \\(\\beta_0\\).\nSlope: The slope is interpreted in terms of the change in the mean of \\(y\\) when \\(x\\) is multiplied by a factor of \\(C\\), since \\(\\log(Cx) = \\log(x) + \\log(C)\\). Thus, when \\(x\\) is multiplied by a factor of \\(C\\), the change in the mean of \\(y\\) is\n\\[\n\\begin{aligned}\n[\\beta_0 + \\beta_1 \\log(Cx)] - [\\beta_0 + \\beta_1 \\log(x)] &= \\beta_1 [\\log(Cx) - \\log(x)] \\\\[10pt]\n& = \\beta_1[\\log(C) + \\log(x) - \\log(x)] \\\\[10pt]\n& = \\beta_1 \\log(C)\n\\end{aligned}\n\\]\nThus the mean of \\(y\\) changes by \\(\\beta_1 \\log(C)\\) units.\nInterpretation: When \\(x\\) is multiplied by a factor of \\(C\\), the mean of \\(y\\) is expected to change by \\(\\beta_1 \\log(C)\\) units. For example, if \\(x\\) is doubled, then the mean of \\(y\\) is expected to change by \\(\\beta_1 \\log(2)\\) units.",
    "crumbs": [
      "Supplemental notes",
      "Log transformations"
    ]
  },
  {
    "objectID": "supplemental/log-transformations.html#log-transformation-on-the-the-response-and-predictor-variable",
    "href": "supplemental/log-transformations.html#log-transformation-on-the-the-response-and-predictor-variable",
    "title": "Log Transformations in Linear Regression",
    "section": "Log-transformation on the the response and predictor variable",
    "text": "Log-transformation on the the response and predictor variable\nSuppose we fit a linear regression model with \\(\\log(x)\\), the log-transformed \\(x\\), as the predictor variable and \\(\\log(y)\\), the log-transformed \\(y\\), as the response variable. Under this model, we assume a linear relationship exists between \\(\\log(x)\\) and \\(\\log(y)\\), such that \\(\\log(y) \\sim N(\\beta_0 + \\beta_1 \\log(x), \\sigma^2)\\) for some \\(\\beta_0\\), \\(\\beta_1\\) and \\(\\sigma^2\\). In other words, we can model the relationship between \\(\\log(x)\\) and \\(\\log(y)\\) using the model in Equation¬†5.\n\\[\n\\log(y) = \\beta_0 + \\beta_1 \\log(x)\n\\tag{5}\\]\nBecause the response variable is log-transformed, the interpretations on the original scale will be in terms of the median of \\(y\\) (see the section on the log-transformed response variable for more detail).\nIntercept: The intercept is the mean of \\(y\\) when \\(\\log(x) = 0\\), i.e.¬†\\(x = 1\\). Therefore, when \\(\\log(x) = 0\\),\n\\[\n\\begin{aligned}\n&\\log(y) = \\beta_0 + \\beta_1 \\times 0 = \\beta_0 \\\\[10pt]\n\\Rightarrow &y = \\exp\\{\\beta_0\\}\n\\end{aligned}\n\\]\nInterpretation: When \\(x = 1\\) \\((\\log(x) = 0)\\), the median of \\(y\\) is expected to be \\(\\exp\\{\\beta_0\\}\\).\nSlope: The slope is interpreted in terms of the change in the median \\(y\\) when \\(x\\) is multiplied by a factor of \\(C\\), since \\(\\log(Cx) = \\log(x) + \\log(C)\\). Thus, when \\(x\\) is multiplied by a factor of \\(C\\), the change in the median of \\(y\\) is\n\\[\n\\begin{aligned}\n\\exp\\{[\\beta_0 + \\beta_1 \\log(Cx)] - [\\beta_0 + \\beta_1 \\log(x)]\\} &=\n\\exp\\{\\beta_1 [\\log(Cx) - \\log(x)]\\} \\\\[10pt]\n& = \\exp\\{\\beta_1[\\log(C) + \\log(x) - \\log(x)]\\} \\\\[10pt]\n& = \\exp\\{\\beta_1 \\log(C)\\} = C^{\\beta_1}\n\\end{aligned}\n\\]\nThus, the median of \\(y\\) for \\(Cx\\) is \\(C^{\\beta_1}\\) times the median of \\(y\\) for \\(x\\).\nInterpretation: When \\(x\\) is multiplied by a factor of \\(C\\), the median of \\(y\\) is expected to multiple by a factor of \\(C^{\\beta_1}\\). For example, if \\(x\\) is doubled, then the median of \\(y\\) is expected to multiply by \\(2^{\\beta_1}\\).",
    "crumbs": [
      "Supplemental notes",
      "Log transformations"
    ]
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html",
    "href": "supplemental/model-diagnostics-matrix.html",
    "title": "Model Diagnostics",
    "section": "",
    "text": "Note\n\n\n\nThe following supplemental notes were created by Dr.¬†Maria Tackett for STA 210. They are provided for students who want to dive deeper into the mathematics behind regression and reflect some of the material covered in STA 211: Mathematics of Regression. Additional supplemental notes will be added throughout the semester.\nThis document discusses some of the mathematical details of the model diagnostics - leverage, standardized residuals, and Cook‚Äôs distance. We assume the reader knowledge of the matrix form for multiple linear regression. Please see Matrix Form of Linear Regression for a review.",
    "crumbs": [
      "Supplemental notes",
      "Model diagnostics"
    ]
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#introduction",
    "href": "supplemental/model-diagnostics-matrix.html#introduction",
    "title": "Model Diagnostics",
    "section": "Introduction",
    "text": "Introduction\nSuppose we have \\(n\\) observations. Let the \\(i^{th}\\) be \\((x_{i1}, \\ldots, x_{ip}, y_i)\\), such that \\(x_{i1}, \\ldots, x_{ip}\\) are the explanatory variables (predictors) and \\(y_i\\) is the response variable. We assume the data can be modeled using the least-squares regression model, such that the mean response for a given combination of explanatory variables follows the form in Equation¬†1.\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p\n\\tag{1}\\]\nWe can write the response for the \\(i^{th}\\) observation as shown in Equation¬†2.\n\\[\ny_i = \\beta_0 + \\beta_1 x_{i1} + \\dots + \\beta_p x_{ip} + \\epsilon_i\n\\tag{2}\\]\nsuch that \\(\\epsilon_i\\) is the amount \\(y_i\\) deviates from \\(\\mu\\{y|x_{i1}, \\ldots, x_{ip}\\}\\), the mean response for a given combination of explanatory variables. We assume each \\(\\epsilon_i \\sim N(0,\\sigma^2)\\), where \\(\\sigma^2\\) is a constant variance for the distribution of the response \\(y\\) for any combination of explanatory variables \\(x_1, \\ldots, x_p\\).",
    "crumbs": [
      "Supplemental notes",
      "Model diagnostics"
    ]
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#matrix-form-for-the-regression-model",
    "href": "supplemental/model-diagnostics-matrix.html#matrix-form-for-the-regression-model",
    "title": "Model Diagnostics",
    "section": "Matrix Form for the Regression Model",
    "text": "Matrix Form for the Regression Model\nWe can represent the Equation¬†1 and Equation¬†2 using matrix notation. Let\n\\[\n\\mathbf{Y} = \\begin{bmatrix}y_1 \\\\ y_2 \\\\ \\vdots \\\\y_n\\end{bmatrix}\n\\hspace{15mm}\n\\mathbf{X} = \\begin{bmatrix}x_{11} & x_{12} & \\dots & x_{1p} \\\\\nx_{21} & x_{22} & \\dots & x_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\nx_{n1} & x_{n2} & \\dots & x_{np} \\end{bmatrix}\n\\hspace{15mm}\n\\boldsymbol{\\beta}= \\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\\\ \\vdots \\\\ \\beta_p \\end{bmatrix}\n\\hspace{15mm}\n\\boldsymbol{\\epsilon}= \\begin{bmatrix}\\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{bmatrix}\n\\tag{3}\\]\nThus,\n\\[\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\\]\nTherefore the estimated response for a given combination of explanatory variables and the associated residuals can be written as\n\\[\n\\hat{\\mathbf{Y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\hspace{10mm} \\mathbf{e} = \\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\n\\tag{4}\\]",
    "crumbs": [
      "Supplemental notes",
      "Model diagnostics"
    ]
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#hat-matrix-leverage",
    "href": "supplemental/model-diagnostics-matrix.html#hat-matrix-leverage",
    "title": "Model Diagnostics",
    "section": "Hat Matrix & Leverage",
    "text": "Hat Matrix & Leverage\nRecall from the notes Matrix Form of Linear Regression that \\(\\hat{\\boldsymbol{\\beta}}\\) can be written as the following:\n\\[\n\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}\n\\tag{5}\\]\nCombining Equation¬†4 and Equation¬†5, we can write \\(\\hat{\\mathbf{Y}}\\) as the following:\n\\[\n\\begin{aligned}\n\\hat{\\mathbf{Y}} &= \\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\[10pt]\n&= \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}\\\\\n\\end{aligned}\n\\tag{6}\\]\nWe define the hat matrix as an \\(n \\times n\\) matrix of the form \\(\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\). Thus Equation¬†6 becomes\n\\[\n\\hat{\\mathbf{Y}} = \\mathbf{H}\\mathbf{Y}\n\\tag{7}\\]\nThe diagonal elements of the hat matrix are a measure of how far the predictor variables of each observation are from the means of the predictor variables. For example, \\(h_{ii}\\) is a measure of how far the values of the predictor variables for the \\(i^{th}\\) observation, \\(x_{i1}, x_{i2}, \\ldots, x_{ip}\\), are from the mean values of the predictor variables, \\(\\bar{x}_1, \\bar{x}_2, \\ldots, \\bar{x}_p\\). In the case of simple linear regression, the \\(i^{th}\\) diagonal, \\(h_{ii}\\), can be written as\n\\[\nh_{ii} =  \\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{\\sum_{j=1}^{n}(x_j-\\bar{x})^2}\n\\]\nWe call these diagonal elements, the leverage of each observation.\nThe diagonal elements of the hat matrix have the following properties:\n\n\\(0 \\leq h_ii \\leq 1\\)\n\\(\\sum\\limits_{i=1}^{n} h_{ii} = p+1\\), where \\(p\\) is the number of predictor variables in the model.\nThe mean hat value is \\(\\bar{h} = \\frac{\\sum\\limits_{i=1}^{n} h_{ii}}{n} = \\frac{p+1}{n}\\).\n\nUsing these properties, we consider a point to have high leverage if it has a leverage value that is more than 2 times the average. In other words, observations with leverage greater than \\(\\frac{2(p+1)}{n}\\) are considered to be high leverage points, i.e.¬†outliers in the predictor variables. We are interested in flagging high leverage points, because they may have an influence on the regression coefficients.\nWhen there are high leverage points in the data, the regression line will tend towards those points; therefore, one property of high leverage points is that they tend to have small residuals. We will show this by rewriting the residuals from Equation¬†4 using Equation¬†7.\n\\[\n\\begin{aligned}\n\\mathbf{e} &= \\mathbf{Y} - \\hat{\\mathbf{Y}} \\\\[10pt]\n& = \\mathbf{Y} - \\mathbf{H}\\mathbf{Y} \\\\[10pt]\n&= (1-\\mathbf{H})\\mathbf{Y}\n\\end{aligned}\n\\tag{8}\\]\nNote that the identity matrix and hat matrix are idempotent, i.e.¬†\\(\\mathbf{I}\\mathbf{I} = \\mathbf{I}\\), \\(\\mathbf{H}\\mathbf{H} = \\mathbf{H}\\). Thus, \\((\\mathbf{I} - \\mathbf{H})\\) is also idempotent. These matrices are also symmetric. Using these properties and Equation¬†8, we have that the variance-covariance matrix of the residuals \\(\\boldsymbol{e}\\), is\n\\[\n\\begin{aligned}\nVar(\\mathbf{e}) &= \\mathbf{e}\\mathbf{e}^T \\\\[10pt]\n&=  (1-\\mathbf{H})Var(\\mathbf{Y})^T(1-\\mathbf{H})^T \\\\[10pt]\n&= (1-\\mathbf{H})\\hat{\\sigma}^2(1-\\mathbf{H})^T  \\\\[10pt]\n&= \\hat{\\sigma}^2(1-\\mathbf{H})(1-\\mathbf{H})  \\\\[10pt]\n&= \\hat{\\sigma}^2(1-\\mathbf{H})\n\\end{aligned}\n\\tag{9}\\]\nwhere \\(\\hat{\\sigma}^2 = \\frac{\\sum_{i=1}^{n}e_i^2}{n-p-1}\\) is the estimated regression variance. Thus, the variance of the \\(i^{th}\\) residual is \\(Var(e_i) = \\hat{\\sigma}^2(1-h_{ii})\\). Therefore, the higher the leverage, the smaller the variance of the residual. Because the expected value of the residuals is 0, we conclude that points with high leverage tend to have smaller residuals than points with lower leverage.",
    "crumbs": [
      "Supplemental notes",
      "Model diagnostics"
    ]
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#standardized-residuals",
    "href": "supplemental/model-diagnostics-matrix.html#standardized-residuals",
    "title": "Model Diagnostics",
    "section": "Standardized Residuals",
    "text": "Standardized Residuals\nIn general, we standardize a value by shifting by the expected value and rescaling by the standard deviation (or standard error). Thus, the \\(i^{th}\\) standardized residual takes the form\n\\[\nstd.res_i = \\frac{e_i - E(e_i)}{SE(e_i)}\n\\]\nThe expected value of the residuals is 0, i.e.¬†\\(E(e_i) = 0\\). From Equation¬†9), the standard error of the residual is \\(SE(e_i) = \\hat{\\sigma}\\sqrt{1-h_{ii}}\\). Therefore,\n\\[\nstd.res_i = \\frac{e_i}{\\hat{\\sigma}\\sqrt{1-h_{ii}}}\n\\tag{10}\\]",
    "crumbs": [
      "Supplemental notes",
      "Model diagnostics"
    ]
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#cooks-distance",
    "href": "supplemental/model-diagnostics-matrix.html#cooks-distance",
    "title": "Model Diagnostics",
    "section": "Cook‚Äôs Distance",
    "text": "Cook‚Äôs Distance\nCook‚Äôs distance is a measure of how much each observation influences the model coefficients, and thus the predicted values. The Cook‚Äôs distance for the \\(i^{th}\\) observation can be written as\n\\[\nD_i = \\frac{(\\hat{\\mathbf{Y}} -\\hat{\\mathbf{Y}}_{(i)})^T(\\hat{\\mathbf{Y}} -\\hat{\\mathbf{Y}}_{(i)})}{(p+1)\\hat{\\sigma}}\n\\tag{11}\\]\nwhere \\(\\hat{\\mathbf{Y}}_{(i)}\\) is the vector of predicted values from the model fitted when the \\(i^{th}\\) observation is deleted. Cook‚Äôs Distance can be calculated without deleting observations one at a time, since Equation¬†12 below is mathematically equivalent to Equation¬†11.\n\\[\nD_i = \\frac{1}{p+1}std.res_i^2\\Bigg[\\frac{h_{ii}}{(1-h_{ii})}\\Bigg] = \\frac{e_i^2}{(p+1)\\hat{\\sigma}^2(1-h_{ii})}\\Bigg[\\frac{h_{ii}}{(1-h_{ii})}\\Bigg]\n\\tag{12}\\]",
    "crumbs": [
      "Supplemental notes",
      "Model diagnostics"
    ]
  },
  {
    "objectID": "supplemental/slr-derivations.html",
    "href": "supplemental/slr-derivations.html",
    "title": "Deriving the Least-Squares Estimates for Simple Linear Regression",
    "section": "",
    "text": "Note\n\n\n\nThe following supplemental notes were created by Dr.¬†Maria Tackett for STA 210. They are provided for students who want to dive deeper into the mathematics behind regression and reflect some of the material covered in STA 211: Mathematics of Regression. Additional supplemental notes will be added throughout the semester.\n\n\nThis document contains the mathematical details for deriving the least-squares estimates for slope (\\(\\beta_1\\)) and intercept (\\(\\beta_0\\)). We obtain the estimates, \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\) by finding the values that minimize the sum of squared residuals, as shown in Equation¬†1.\n\\[\nSSR = \\sum\\limits_{i=1}^{n}[y_i - \\hat{y}_i]^2 = [y_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i)]^2 = [y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i]^2\n\\tag{1}\\]\nRecall that we can find the values of \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\) that minimize /eq-ssr by taking the partial derivatives of Equation¬†1 and setting them to 0. Thus, the values of \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\) that minimize the respective partial derivative also minimize the sum of squared residuals. The partial derivatives are shown in Equation¬†2.\n\\[\n\\begin{aligned}\n\\frac{\\partial \\text{SSR}}{\\partial \\hat{\\beta}_1} &= -2 \\sum\\limits_{i=1}^{n}x_i(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i)  \\\\\n\\frac{\\partial \\text{SSR}}{\\partial \\hat{\\beta}_0} &= -2 \\sum\\limits_{i=1}^{n}(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i)\n\\end{aligned}\n\\tag{2}\\]\nThe derivation of deriving \\(\\hat{\\beta}_0\\) is shown in Equation¬†3.\n\\[\n\\begin{aligned}\\frac{\\partial \\text{SSR}}{\\partial \\hat{\\beta}_0} &= -2 \\sum\\limits_{i=1}^{n}(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i) = 0 \\\\&\\Rightarrow -\\sum\\limits_{i=1}^{n}(y_i + \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i) = 0 \\\\&\\Rightarrow - \\sum\\limits_{i=1}^{n}y_i + n\\hat{\\beta}_0 + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i = 0 \\\\&\\Rightarrow n\\hat{\\beta}_0  = \\sum\\limits_{i=1}^{n}y_i - \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i \\\\&\\Rightarrow \\hat{\\beta}_0  = \\frac{1}{n}\\Big(\\sum\\limits_{i=1}^{n}y_i - \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i\\Big)\\\\&\\Rightarrow \\hat{\\beta}_0  = \\bar{y} - \\hat{\\beta}_1 \\bar{x} \\\\\\end{aligned}\n\\tag{3}\\]\nThe derivation of \\(\\hat{\\beta}_1\\) using the \\(\\hat{\\beta}_0\\) we just derived is shown in Equation¬†4.\n\\[\n\\begin{aligned}&\\frac{\\partial \\text{SSR}}{\\partial \\hat{\\beta}_1} = -2 \\sum\\limits_{i=1}^{n}x_i(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i) = 0  \\\\&\\Rightarrow -\\sum\\limits_{i=1}^{n}x_iy_i + \\hat{\\beta}_0\\sum\\limits_{i=1}^{n}x_i + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = 0 \\\\\\text{(Fill in }\\hat{\\beta}_0\\text{)}&\\Rightarrow -\\sum\\limits_{i=1}^{n}x_iy_i + (\\bar{y} - \\hat{\\beta}_1\\bar{x})\\sum\\limits_{i=1}^{n}x_i + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = 0 \\\\&\\Rightarrow  (\\bar{y} - \\hat{\\beta}_1\\bar{x})\\sum\\limits_{i=1}^{n}x_i + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = \\sum\\limits_{i=1}^{n}x_iy_i \\\\&\\Rightarrow \\bar{y}\\sum\\limits_{i=1}^{n}x_i - \\hat{\\beta}_1\\bar{x}\\sum\\limits_{i=1}^{n}x_i + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = \\sum\\limits_{i=1}^{n}x_iy_i \\\\&\\Rightarrow n\\bar{y}\\bar{x} - \\hat{\\beta}_1n\\bar{x}^2 + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = \\sum\\limits_{i=1}^{n}x_iy_i \\\\&\\Rightarrow \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 - \\hat{\\beta}_1n\\bar{x}^2  = \\sum\\limits_{i=1}^{n}x_iy_i - n\\bar{y}\\bar{x} \\\\&\\Rightarrow \\hat{\\beta}_1\\Big(\\sum\\limits_{i=1}^{n}x_i^2 -n\\bar{x}^2\\Big)  = \\sum\\limits_{i=1}^{n}x_iy_i - n\\bar{y}\\bar{x} \\\\ &\\hat{\\beta}_1 = \\frac{\\sum\\limits_{i=1}^{n}x_iy_i - n\\bar{y}\\bar{x}}{\\sum\\limits_{i=1}^{n}x_i^2 -n\\bar{x}^2}\\end{aligned}\n\\tag{4}\\]\nTo write \\(\\hat{\\beta}_1\\) in a form that‚Äôs more recognizable, we will use the following:\n\\[\n\\sum x_iy_i - n\\bar{y}\\bar{x} = \\sum(x - \\bar{x})(y - \\bar{y}) = (n-1)\\text{Cov}(x,y)\n\\tag{5}\\]\n\\[\n\\sum x_i^2 - n\\bar{x}^2 - \\sum(x - \\bar{x})^2 = (n-1)s_x^2\n\\tag{6}\\]\nwhere \\(\\text{Cov}(x,y)\\) is the covariance of \\(x\\) and \\(y\\), and \\(s_x^2\\) is the sample variance of \\(x\\) (\\(s_x\\) is the sample standard deviation).\nThus, applying Equation¬†5 and Equation¬†6, we have\n\\[\n\\begin{aligned}\\hat{\\beta}_1 &= \\frac{\\sum\\limits_{i=1}^{n}x_iy_i - n\\bar{y}\\bar{x}}{\\sum\\limits_{i=1}^{n}x_i^2 -n\\bar{x}^2} \\\\&= \\frac{\\sum\\limits_{i=1}^{n}(x-\\bar{x})(y-\\bar{y})}{\\sum\\limits_{i=1}^{n}(x-\\bar{x})^2}\\\\&= \\frac{(n-1)\\text{Cov}(x,y)}{(n-1)s_x^2}\\\\&= \\frac{\\text{Cov}(x,y)}{s_x^2}\\end{aligned}\n\\tag{7}\\]\nThe correlation between \\(x\\) and \\(y\\) is \\(r = \\frac{\\text{Cov}(x,y)}{s_x s_y}\\). Thus, \\(\\text{Cov}(x,y) = r s_xs_y\\). Plugging this into Equation¬†7, we have\n\\[\n\\hat{\\beta}_1 = \\frac{\\text{Cov}(x,y)}{s_x^2} = r\\frac{s_ys_x}{s_x^2} = r\\frac{s_y}{s_x}\n\\tag{8}\\]",
    "crumbs": [
      "Supplemental notes",
      "SLR derivations"
    ]
  },
  {
    "objectID": "weeks/week-10.html",
    "href": "weeks/week-10.html",
    "title": "Week 10",
    "section": "",
    "text": "Important\n\n\n\nDue date: Project proposal due Fri, Mar 18 at 5:00 pm.",
    "crumbs": [
      "Weekly materials",
      "Week 10"
    ]
  },
  {
    "objectID": "weeks/week-10.html#prepare",
    "href": "weeks/week-10.html#prepare",
    "title": "Week 10",
    "section": "Prepare",
    "text": "Prepare\nüìñ Read Introduction to Modern Statistics, Chp 9: Logistic regression",
    "crumbs": [
      "Weekly materials",
      "Week 10"
    ]
  },
  {
    "objectID": "weeks/week-10.html#participate",
    "href": "weeks/week-10.html#participate",
    "title": "Week 10",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lecture 18 - Logistic regression\nüñ•Ô∏è Lecture 19 - Probabilities, odds, odds ratios",
    "crumbs": [
      "Weekly materials",
      "Week 10"
    ]
  },
  {
    "objectID": "weeks/week-10.html#practice",
    "href": "weeks/week-10.html#practice",
    "title": "Week 10",
    "section": "Practice",
    "text": "Practice\nüìã Application Exercise 9 - Odds",
    "crumbs": [
      "Weekly materials",
      "Week 10"
    ]
  },
  {
    "objectID": "weeks/week-10.html#perform",
    "href": "weeks/week-10.html#perform",
    "title": "Week 10",
    "section": "Perform",
    "text": "Perform\n‚úçÔ∏è HW 3 - Logistic regression and log transformation\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly materials",
      "Week 10"
    ]
  },
  {
    "objectID": "weeks/week-12.html",
    "href": "weeks/week-12.html",
    "title": "Week 12",
    "section": "",
    "text": "Important\n\n\n\nDue dates: None.",
    "crumbs": [
      "Weekly materials",
      "Week 12"
    ]
  },
  {
    "objectID": "weeks/week-12.html#prepare",
    "href": "weeks/week-12.html#prepare",
    "title": "Week 12",
    "section": "Prepare",
    "text": "Prepare\nüìñ Read Introduction to Modern Statistics, Chp 26: Inference for logistic regression",
    "crumbs": [
      "Weekly materials",
      "Week 12"
    ]
  },
  {
    "objectID": "weeks/week-12.html#participate",
    "href": "weeks/week-12.html#participate",
    "title": "Week 12",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lecture 22 - LR: Inference + conditions\nüñ•Ô∏è Lecture 23 - Multinomial logistic regression (MultiLR)",
    "crumbs": [
      "Weekly materials",
      "Week 12"
    ]
  },
  {
    "objectID": "weeks/week-12.html#practice",
    "href": "weeks/week-12.html#practice",
    "title": "Week 12",
    "section": "Practice",
    "text": "Practice\nNo application exercises this week.",
    "crumbs": [
      "Weekly materials",
      "Week 12"
    ]
  },
  {
    "objectID": "weeks/week-12.html#perform",
    "href": "weeks/week-12.html#perform",
    "title": "Week 12",
    "section": "Perform",
    "text": "Perform\n‚úçÔ∏è HW 4 - Multinomial logistic regression\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly materials",
      "Week 12"
    ]
  },
  {
    "objectID": "weeks/week-14.html",
    "href": "weeks/week-14.html",
    "title": "Week 14",
    "section": "",
    "text": "Important\n\n\n\nDue dates: Friday, April 15 - Project peer review of drafts",
    "crumbs": [
      "Weekly materials",
      "Week 14"
    ]
  },
  {
    "objectID": "weeks/week-14.html#participate",
    "href": "weeks/week-14.html#participate",
    "title": "Week 14",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lecture 26 - MultiLR: Predictive models (cont.)\nüñ•Ô∏è Lecture 27 - Exam 3 Review",
    "crumbs": [
      "Weekly materials",
      "Week 14"
    ]
  },
  {
    "objectID": "weeks/week-14.html#practice",
    "href": "weeks/week-14.html#practice",
    "title": "Week 14",
    "section": "Practice",
    "text": "Practice\nüìã Application Exercise 12 - Exam 3 Review",
    "crumbs": [
      "Weekly materials",
      "Week 14"
    ]
  },
  {
    "objectID": "weeks/week-14.html#perform",
    "href": "weeks/week-14.html#perform",
    "title": "Week 14",
    "section": "Perform",
    "text": "Perform\n‚úçÔ∏è Project - Peer review of drafts\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly materials",
      "Week 14"
    ]
  },
  {
    "objectID": "weeks/week-2.html",
    "href": "weeks/week-2.html",
    "title": "Week 2",
    "section": "",
    "text": "Important\n\n\n\n\nClasses are virtual this week. Find Zoom links here.\nDue dates:\n\nLab 1: Fri, Jan 14, 5pm ET\nAE 1: Sun, Jan 16, 11:59pm ET",
    "crumbs": [
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week-2.html#prepare",
    "href": "weeks/week-2.html#prepare",
    "title": "Week 2",
    "section": "Prepare",
    "text": "Prepare\nüìñ Read Introduction to Modern Statistics, Chp 7: Linear regression with a single predictor",
    "crumbs": [
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week-2.html#participate",
    "href": "weeks/week-2.html#participate",
    "title": "Week 2",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lab 1 - Meet the toolkit\nüñ•Ô∏è Lecture 2 - Simple linear regression\nüñ•Ô∏è Lecture 3 - Model fitting in R with tidymodels",
    "crumbs": [
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week-2.html#practice",
    "href": "weeks/week-2.html#practice",
    "title": "Week 2",
    "section": "Practice",
    "text": "Practice\nüìã Application Exercise 1 - Bike rentals in DC (Post-class note: complete only Part 1 - Daily counts and temperature)",
    "crumbs": [
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week-2.html#perform",
    "href": "weeks/week-2.html#perform",
    "title": "Week 2",
    "section": "Perform",
    "text": "Perform\n‚å®Ô∏è Lab 1 - Meet the toolkit\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week-4.html",
    "href": "weeks/week-4.html",
    "title": "Week 4",
    "section": "",
    "text": "Important\n\n\n\n\nIf you can‚Äôt be in class for the lectures, you can watch the live stream or watch the recording later on Panopto.\nDue dates:\n\nHW 1: Fri, Jan 28, 5pm ET\nLab 1: Fri, Jan 28, 5pm ET",
    "crumbs": [
      "Weekly materials",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week-4.html#prepare",
    "href": "weeks/week-4.html#prepare",
    "title": "Week 4",
    "section": "Prepare",
    "text": "Prepare\nüìñ Read Introduction to Modern Statistics, Sec 24.4: Mathematical model for testing the slope\nüìñ Read Introduction to Modern Statistics, Sec 24.5: Mathematical model, interval for the slope\nüìñ Read Introduction to Modern Statistics, Sec 24.6: Checking model conditions\nüìñ Read Introduction to Modern Statistics, Sec 24.7: Chapter review",
    "crumbs": [
      "Weekly materials",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week-4.html#participate",
    "href": "weeks/week-4.html#participate",
    "title": "Week 4",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lab 2 - College scorecard\nüñ•Ô∏è Lecture 6 - SLR: Mathematical models for inference\nüñ•Ô∏è Lecture 7 - SLR: Model diagnostics",
    "crumbs": [
      "Weekly materials",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week-4.html#practice",
    "href": "weeks/week-4.html#practice",
    "title": "Week 4",
    "section": "Practice",
    "text": "Practice\nüìã Application Exercise 3 - Checking model conditions",
    "crumbs": [
      "Weekly materials",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week-4.html#perform",
    "href": "weeks/week-4.html#perform",
    "title": "Week 4",
    "section": "Perform",
    "text": "Perform\n‚å®Ô∏è Lab 2 - College scorecard\n‚úçÔ∏è HW 1 - In-person voting trends\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly materials",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week-6.html",
    "href": "weeks/week-6.html",
    "title": "Week 6",
    "section": "",
    "text": "Important\n\n\n\nDue dates: Exam 1 - Mon, Feb 7 at 11:59pm",
    "crumbs": [
      "Weekly materials",
      "Week 6"
    ]
  },
  {
    "objectID": "weeks/week-6.html#prepare",
    "href": "weeks/week-6.html#prepare",
    "title": "Week 6",
    "section": "Prepare",
    "text": "Prepare\nNo reading (take a break after the exam! üò¥)",
    "crumbs": [
      "Weekly materials",
      "Week 6"
    ]
  },
  {
    "objectID": "weeks/week-6.html#participate",
    "href": "weeks/week-6.html#participate",
    "title": "Week 6",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lecture 10 - MLR: Types of predictors\nüñ•Ô∏è Lecture 11 - MLR: Model comparison",
    "crumbs": [
      "Weekly materials",
      "Week 6"
    ]
  },
  {
    "objectID": "weeks/week-6.html#practice",
    "href": "weeks/week-6.html#practice",
    "title": "Week 6",
    "section": "Practice",
    "text": "Practice\nNo application exercises",
    "crumbs": [
      "Weekly materials",
      "Week 6"
    ]
  },
  {
    "objectID": "weeks/week-6.html#perform",
    "href": "weeks/week-6.html#perform",
    "title": "Week 6",
    "section": "Perform",
    "text": "Perform\nNo lab\n‚úÖ Exam 1\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly materials",
      "Week 6"
    ]
  },
  {
    "objectID": "weeks/week-8.html",
    "href": "weeks/week-8.html",
    "title": "Week 8",
    "section": "",
    "text": "Important\n\n\n\nDue date: Lab 4 - Friday, Feb 25",
    "crumbs": [
      "Weekly materials",
      "Week 8"
    ]
  },
  {
    "objectID": "weeks/week-8.html#prepare",
    "href": "weeks/week-8.html#prepare",
    "title": "Week 8",
    "section": "Prepare",
    "text": "Prepare\nüìñ Read Tidy Modeling in R Chp 10: Resampling for evaluating performance",
    "crumbs": [
      "Weekly materials",
      "Week 8"
    ]
  },
  {
    "objectID": "weeks/week-8.html#participate",
    "href": "weeks/week-8.html#participate",
    "title": "Week 8",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lecture 14 - MLR: Cross validation\nüñ•Ô∏è Lecture 15 - Exam 2 review",
    "crumbs": [
      "Weekly materials",
      "Week 8"
    ]
  },
  {
    "objectID": "weeks/week-8.html#practice",
    "href": "weeks/week-8.html#practice",
    "title": "Week 8",
    "section": "Practice",
    "text": "Practice\nApplication Exercise 6 - The office - CV\nApplication Exercise 7 - Exam 2 Review",
    "crumbs": [
      "Weekly materials",
      "Week 8"
    ]
  },
  {
    "objectID": "weeks/week-8.html#perform",
    "href": "weeks/week-8.html#perform",
    "title": "Week 8",
    "section": "Perform",
    "text": "Perform\n‚å®Ô∏è Lab 4 - The Office, another look\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly materials",
      "Week 8"
    ]
  }
]